{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "constraint_baseline_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9eedbbdf63394d96a9288b66e51dbae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cae0146cd5e94590b9e99a7ed7ba9251",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b27cba17c3146b28b2bf90348826dcb",
              "IPY_MODEL_4a5c14971c2e43fd8857a1e8a9634966"
            ]
          }
        },
        "cae0146cd5e94590b9e99a7ed7ba9251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b27cba17c3146b28b2bf90348826dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_efd3386524dd4b0e8a9bd02a60d66560",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac0c516fcd9b46d8af212e6d5b3f896e"
          }
        },
        "4a5c14971c2e43fd8857a1e8a9634966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f389b51500aa4b35a286e9e2290ad92b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.61MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c08443c0cc44b758483de874f3e3a94"
          }
        },
        "efd3386524dd4b0e8a9bd02a60d66560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac0c516fcd9b46d8af212e6d5b3f896e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f389b51500aa4b35a286e9e2290ad92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c08443c0cc44b758483de874f3e3a94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cde4bb042971412f8e16695dd6d2e3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_83d4e91722a9433a9eecebf9f3172c67",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b9eedf58e86a4a29bdc3b8d710a40151",
              "IPY_MODEL_0a8e4a71116145218b2c9246494b77af"
            ]
          }
        },
        "83d4e91722a9433a9eecebf9f3172c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9eedf58e86a4a29bdc3b8d710a40151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7a14fc517bec4b8ca96a0ccb29933a6b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7da6db06f5e64c64ba170b5e1fd57ef1"
          }
        },
        "0a8e4a71116145218b2c9246494b77af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6fcb4f751c7f47f9a1669e39c6ef9c8b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.54kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03f0d524274b44bb840faa6f03f117e4"
          }
        },
        "7a14fc517bec4b8ca96a0ccb29933a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7da6db06f5e64c64ba170b5e1fd57ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fcb4f751c7f47f9a1669e39c6ef9c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03f0d524274b44bb840faa6f03f117e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d48d3f3a68b4b47a4a90e1b18595826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_68f22f7e1780428b942fa09569185f49",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d1ec708853484e01940c7e2d5b6d7d08",
              "IPY_MODEL_d221f7a921de4adf8cff5eb89833efb1"
            ]
          }
        },
        "68f22f7e1780428b942fa09569185f49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1ec708853484e01940c7e2d5b6d7d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7fc17eb65643472690ec46bf2a2ddc9b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_751c634c787d4c7fa217e34b787e00b5"
          }
        },
        "d221f7a921de4adf8cff5eb89833efb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cbdf055efbeb4abe8a9e4cea4b95a180",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 61.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c6528c0ca9e4e859afc265ffc4ed13b"
          }
        },
        "7fc17eb65643472690ec46bf2a2ddc9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "751c634c787d4c7fa217e34b787e00b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbdf055efbeb4abe8a9e4cea4b95a180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c6528c0ca9e4e859afc265ffc4ed13b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keshav22bansal/BAKSA_IITK/blob/master/constraint_baseline_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kg3RKlSB1Ko"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdFQndZfC8XO"
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1xQ8j3PpN5m",
        "outputId": "9ea8fceb-33f5-4fe6-86a1-941fc057c4b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')  \n",
        "PROJECT_PATH = \"/content/gdrive/My Drive/Constraint/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0dKoOr_z_Xk",
        "outputId": "6eb13834-1bc1-4b8b-e67d-5c6e7ca2201b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%mkdir -p \"{PROJECT_PATH}\"\n",
        "%cd \"{PROJECT_PATH}\"\n",
        "!git clone https://github.com/keshav22bansal/covid_fake_news_constraint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Constraint\n",
            "fatal: destination path 'covid_fake_news_constraint' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQQ6FkNcv-ae",
        "outputId": "17d49c92-30bd-4393-8ffd-ccd0044ecf21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "print(PROJECT_PATH)\n",
        "data_path = os.path.join(PROJECT_PATH,\"covid_fake_news_constraint/dataset\")\n",
        "train_name = \"Constraint_English_Train.csv\"\n",
        "validation_name = \"Constraint_English_Val.csv\"\n",
        "model_save_name = \"constraint_baseline1.model\"\n",
        "bert_model = \"bert-base-uncased\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Constraint/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThOo8L-9sU7n"
      },
      "source": [
        "import sys\n",
        "sys.path.append(data_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hebOrRmGWfj",
        "outputId": "32ca523b-1481-4814-9070-4614f8d0223b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/34/fb092588df61bf33f113ade030d1cbe74fb73a0353648f8dd938a223dce7/transformers-3.5.0-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 21.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 10.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 10.8MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 9.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 9.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 9.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 9.5MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 9.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92kB 9.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102kB 9.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112kB 9.9MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 9.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133kB 9.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143kB 9.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153kB 9.9MB/s eta 0:00:01\r\u001b[K     |████                            | 163kB 9.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174kB 9.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184kB 9.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 204kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 235kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 245kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 286kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 307kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 317kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 327kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 348kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 358kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 389kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 399kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 430kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 440kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 460kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 471kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 481kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 501kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 512kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 522kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 542kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 552kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 583kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 593kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 614kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 624kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 634kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 655kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 665kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 675kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 696kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 706kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 716kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 727kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 737kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 747kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 757kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 768kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 778kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 788kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 798kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 808kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 819kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 829kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 839kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 849kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 860kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 870kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 880kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 890kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 901kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 911kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 921kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 931kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 942kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 952kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 962kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 972kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 983kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 993kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0MB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0MB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0MB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1MB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1MB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1MB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1MB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2MB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2MB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 50.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=c7d35b6124c19213a115a7870befd11210695c9b62d075dd9c9459393f2c2d3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao9CbNtzv5lF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzN9lV1ZGhY2",
        "outputId": "89c05fcb-479f-44fa-8891-25ddce07ef0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "9eedbbdf63394d96a9288b66e51dbae8",
            "cae0146cd5e94590b9e99a7ed7ba9251",
            "7b27cba17c3146b28b2bf90348826dcb",
            "4a5c14971c2e43fd8857a1e8a9634966",
            "efd3386524dd4b0e8a9bd02a60d66560",
            "ac0c516fcd9b46d8af212e6d5b3f896e",
            "f389b51500aa4b35a286e9e2290ad92b",
            "9c08443c0cc44b758483de874f3e3a94"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9eedbbdf63394d96a9288b66e51dbae8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YriUeQu3G47w",
        "outputId": "38c5711a-3e42-4948-c064-1d13bec466f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(tokenizer.vocab)\n",
        "tokens = tokenizer.tokenize('how ARE you ')\n",
        "\n",
        "print(tokens)\n",
        "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(indexes)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['how', 'are', 'you']\n",
            "[2129, 2024, 2017]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_lDr2XzHEuN",
        "outputId": "686f4a65-f9ea-47bb-b573-1aaa3d95ecf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)\n",
        "\n",
        "\n",
        "# We can get the indexes of the special tokens by converting them using the vocabulary...\n",
        "\n",
        "# In[7]:\n",
        "\n",
        "\n",
        "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
        "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
        "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
        "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)\n",
        "\n",
        "\n",
        "# ...or by explicitly getting them from the tokenizer.\n",
        "\n",
        "# In[8]:\n",
        "\n",
        "\n",
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)\n",
        "\n",
        "\n",
        "# Another thing we need to handle is that the model was trained on sequences with a defined maximum length - it does not know how to handle sequences longer than it has been trained on. We can get the maximum length of these input sizes by checking the `max_model_input_sizes` for the version of the transformer we want to use. In this case, it is 512 tokens.\n",
        "\n",
        "# In[9]:\n",
        "\n",
        "\n",
        "max_input_length = tokenizer.max_model_input_sizes[bert_model]\n",
        "\n",
        "print(max_input_length)\n",
        "\n",
        "\n",
        "# Previously we have used the `spaCy` tokenizer to tokenize our examples. However we now need to define a function that we will pass to our `TEXT` field that will handle all the tokenization for us. It will also cut down the number of tokens to a maximum length. Note that our maximum length is 2 less than the actual maximum length. This is because we need to append two tokens to each sequence, one to the start and one to the end.\n",
        "\n",
        "# In[10]:\n",
        "\n",
        "\n",
        "def tokenize_and_cut(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence) \n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    min_length = 5\n",
        "    if len(tokens) < min_length:\n",
        "      tokens = [init_token]*min_length\n",
        "    return tokens\n",
        "\n",
        "\n",
        "# Now we define our fields. The transformer expects the batch dimension to be first, so we set `batch_first = True`. As we already have the vocabulary for our text, provided by the transformer we set `use_vocab = False` to tell torchtext that we'll be handling the vocabulary side of things. We pass our `tokenize_and_cut` function as the tokenizer. The `preprocessing` argument is a function that takes in the example after it has been tokenized, this is where we will convert the tokens to their indexes. Finally, we define the special tokens - making note that we are defining them to be their index value and not their string value, i.e. `100` instead of `[UNK]` This is because the sequences will already be converted into indexes.\n",
        "# \n",
        "# We define the label field as before.\n",
        "\n",
        "# In[87]:\n",
        "\n",
        "\n",
        "from torchtext import data\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n",
            "101 102 0 100\n",
            "101 102 0 100\n",
            "512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'torchtext.data' from '/usr/local/lib/python3.6/dist-packages/torchtext/data/__init__.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unFFscF5GkpA"
      },
      "source": [
        "UID = data.Field(sequential=False, use_vocab=False, pad_token=None)\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = tokenize_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField()\n",
        "\n",
        "# We load the data and create the validation splits as before.\n",
        "\n",
        "# In[89]:\n",
        "\n",
        "\n",
        "# from torchtext import datasets\n",
        "# fields = {'uid':('uid',UID),'text': ('text', TEXT), 'label': ('label', LABEL) }\n",
        "fields = [('id',UID),('tweet', TEXT),('label', LABEL)]\n",
        "train_data, test_data = data.TabularDataset.splits(\n",
        "                                        path = data_path,\n",
        "                                        train = train_name,\n",
        "                                        test = validation_name,\n",
        "                                        format = 'csv',\n",
        "                                        fields = fields,\n",
        "                                        skip_header = True\n",
        ")\n",
        "# train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "# valid_data = train_data\n",
        "train_data, valid_data = train_data.split(0.8,random_state = random.seed(SEED))\n",
        "\n",
        "\n",
        "# In[90]:\n",
        "\n",
        "\n",
        "# print(vars(train_data[1]))\n",
        "# print(tokenizer.convert_ids_to_tokens(vars(test_data[331])))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMy50hu2HQKe",
        "outputId": "3f24ef2c-74c6-4a36-b589-cee7a80c3ec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data)}\")\n",
        "print(f\"Number of testing examples: {len(test_data)}\")\n",
        "\n",
        "\n",
        "# We can check an example and ensure that the text has already been numericalized.\n",
        "\n",
        "# In[92]:\n",
        "\n",
        "\n",
        "# print(vars(train_data.examples[0])['label'])\n",
        "print(vars(train_data.examples[1]))\n",
        "print(vars(train_data.examples[2]))\n",
        "\n",
        "\n",
        "\n",
        "# We can use the `convert_ids_to_tokens` to transform these indexes back into readable tokens.\n",
        "\n",
        "# In[93]:\n",
        "\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[0])['tweet'])\n",
        "\n",
        "print(tokens)\n",
        "\n",
        "\n",
        "# Although we've handled the vocabulary for the text, we still need to build the vocabulary for the labels.\n",
        "\n",
        "# In[94]:\n",
        "\n",
        "UID.build_vocab(train_data)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "\n",
        "# In[95]:\n",
        "\n",
        "\n",
        "print(LABEL.vocab.stoi)\n",
        "print(UID.vocab.stoi)\n",
        "\n",
        "# As before, we create the iterators. Ideally we want to use the largest batch size that we can as I've found this gives the best results for transformers.\n",
        "\n",
        "# In[96]:\n",
        "\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 5136\n",
            "Number of validation examples: 1284\n",
            "Number of testing examples: 2140\n",
            "{'id': '3611', 'tweet': [1001, 14234, 6494, 3619, 24759, 4630, 2478, 1048, 24335, 8458, 10085, 17250, 2139, 10814, 3436, 15946, 1004, 23713, 1025, 3115, 6032, 10047, 23041, 2891, 6279, 20110, 3258, 2012, 1996, 4578, 1997, 1996, 1001, 2522, 17258, 16147, 6090, 3207, 7712, 1999, 1001, 16392, 16770, 1024, 1013, 1013, 1056, 1012, 2522, 1013, 6227, 16558, 2015, 3501, 20974, 2692, 2050, 1030, 17306, 13663, 2015, 18827, 1030, 7020, 14971, 27967, 1030, 2003, 7382, 5488, 2094, 5420, 1030, 19363, 3981, 4313, 20492, 2072, 1030, 14383, 11493, 8113, 2100, 2278, 1030, 24582, 4430, 2078, 20048, 11493, 4886, 1001, 5107, 7875, 20528, 6593, 16770, 1024, 1013, 1013, 1056, 1012, 2522, 1013, 1054, 2140, 4160, 16275, 5558, 2546, 3501, 2549], 'label': 'fake'}\n",
            "{'id': '958', 'tweet': [3188, 2000, 1996, 3171, 2091, 22299, 3303, 2011, 2522, 17258, 1011, 2539, 1010, 1996, 2142, 2163, 4610, 2001, 2012, 2049, 4602, 2412, 4672, 1012], 'label': 'fake'}\n",
            "['the', 'vaccine', 'for', 'corona', '##virus', 'is', 'ready', '.', 'us', 'president', 'donald', 'trump', 'has', 'announced', 'that', 'roche', 'medical', 'company', 'will', 'launch', 'it', '.']\n",
            "defaultdict(<function _default_unk_index at 0x7f35502ab378>, {'real': 0, 'fake': 1})\n",
            "defaultdict(<function _default_unk_index at 0x7f35502ab378>, {'<unk>': 0, '1': 1, '10': 2, '100': 3, '1001': 4, '1002': 5, '1003': 6, '1004': 7, '1006': 8, '1007': 9, '1008': 10, '1009': 11, '101': 12, '1010': 13, '1011': 14, '1012': 15, '1013': 16, '1014': 17, '1015': 18, '1016': 19, '1017': 20, '1019': 21, '102': 22, '1020': 23, '1022': 24, '1023': 25, '1024': 26, '1025': 27, '1026': 28, '1027': 29, '1028': 30, '1029': 31, '103': 32, '1030': 33, '1032': 34, '1033': 35, '1034': 36, '1035': 37, '1036': 38, '1037': 39, '1038': 40, '104': 41, '1041': 42, '1044': 43, '1045': 44, '1046': 45, '1048': 46, '1049': 47, '105': 48, '1050': 49, '1051': 50, '1053': 51, '1054': 52, '1055': 53, '1056': 54, '1057': 55, '1059': 56, '1060': 57, '1062': 58, '1063': 59, '1064': 60, '1065': 61, '1066': 62, '1067': 63, '1068': 64, '1070': 65, '1072': 66, '1073': 67, '1074': 68, '1075': 69, '1076': 70, '1077': 71, '1079': 72, '108': 73, '1081': 74, '1082': 75, '1083': 76, '1085': 77, '1086': 78, '1087': 79, '1089': 80, '1091': 81, '1092': 82, '1094': 83, '1095': 84, '1096': 85, '1097': 86, '1098': 87, '1099': 88, '11': 89, '1101': 90, '1102': 91, '1103': 92, '1104': 93, '1105': 94, '1106': 95, '1107': 96, '1109': 97, '111': 98, '1111': 99, '1112': 100, '1113': 101, '1114': 102, '1116': 103, '1117': 104, '1118': 105, '1119': 106, '112': 107, '1120': 108, '1121': 109, '1122': 110, '1123': 111, '1124': 112, '1126': 113, '1127': 114, '1128': 115, '1129': 116, '113': 117, '1130': 118, '1131': 119, '1132': 120, '1133': 121, '1135': 122, '1136': 123, '1137': 124, '1138': 125, '1139': 126, '114': 127, '1140': 128, '1141': 129, '1142': 130, '1145': 131, '1146': 132, '1147': 133, '1148': 134, '1149': 135, '115': 136, '1150': 137, '1151': 138, '1152': 139, '1153': 140, '1154': 141, '1157': 142, '1158': 143, '1159': 144, '1160': 145, '1163': 146, '1164': 147, '1165': 148, '1166': 149, '1168': 150, '1169': 151, '1170': 152, '1171': 153, '1172': 154, '1173': 155, '1174': 156, '1175': 157, '1176': 158, '1177': 159, '1178': 160, '1179': 161, '118': 162, '1180': 163, '1181': 164, '1182': 165, '1184': 166, '1185': 167, '1186': 168, '1187': 169, '1188': 170, '1189': 171, '119': 172, '1191': 173, '1192': 174, '1193': 175, '1196': 176, '1197': 177, '1198': 178, '12': 179, '120': 180, '1200': 181, '1201': 182, '1202': 183, '1203': 184, '1204': 185, '1205': 186, '1206': 187, '1207': 188, '1209': 189, '121': 190, '1210': 191, '1212': 192, '1213': 193, '1214': 194, '1215': 195, '1217': 196, '1218': 197, '1219': 198, '122': 199, '1220': 200, '1222': 201, '1223': 202, '1224': 203, '1225': 204, '1226': 205, '1227': 206, '1228': 207, '123': 208, '1230': 209, '1231': 210, '1232': 211, '1233': 212, '1234': 213, '1235': 214, '1236': 215, '1237': 216, '1239': 217, '124': 218, '1240': 219, '1241': 220, '1242': 221, '1243': 222, '1244': 223, '1245': 224, '1246': 225, '1247': 226, '1248': 227, '125': 228, '1250': 229, '1251': 230, '1252': 231, '1253': 232, '1254': 233, '1255': 234, '1256': 235, '1257': 236, '1258': 237, '1259': 238, '126': 239, '1260': 240, '1262': 241, '1263': 242, '1264': 243, '1265': 244, '1266': 245, '1267': 246, '1268': 247, '1269': 248, '127': 249, '1270': 250, '1271': 251, '1272': 252, '1273': 253, '1274': 254, '1278': 255, '1279': 256, '128': 257, '1280': 258, '1281': 259, '1283': 260, '1284': 261, '1285': 262, '1286': 263, '1287': 264, '1288': 265, '129': 266, '1290': 267, '1291': 268, '1292': 269, '1293': 270, '1294': 271, '1296': 272, '1297': 273, '1298': 274, '1299': 275, '13': 276, '130': 277, '1300': 278, '1301': 279, '1302': 280, '1303': 281, '1306': 282, '1307': 283, '1308': 284, '131': 285, '1310': 286, '1311': 287, '1312': 288, '1313': 289, '1314': 290, '1315': 291, '1316': 292, '1318': 293, '1319': 294, '132': 295, '1320': 296, '1321': 297, '1322': 298, '1323': 299, '1325': 300, '1326': 301, '1328': 302, '133': 303, '1331': 304, '1332': 305, '1333': 306, '1334': 307, '1335': 308, '1336': 309, '1337': 310, '1338': 311, '1339': 312, '134': 313, '1340': 314, '1341': 315, '1343': 316, '1344': 317, '1345': 318, '1346': 319, '1348': 320, '1349': 321, '135': 322, '1350': 323, '1351': 324, '1352': 325, '1353': 326, '1355': 327, '1356': 328, '1357': 329, '1359': 330, '136': 331, '1360': 332, '1361': 333, '1362': 334, '1363': 335, '1365': 336, '1368': 337, '1369': 338, '137': 339, '1370': 340, '1372': 341, '1373': 342, '1374': 343, '1375': 344, '1376': 345, '1377': 346, '1378': 347, '1379': 348, '138': 349, '1380': 350, '1382': 351, '1384': 352, '1385': 353, '1386': 354, '1387': 355, '1389': 356, '139': 357, '1391': 358, '1393': 359, '1395': 360, '1396': 361, '1397': 362, '1398': 363, '14': 364, '140': 365, '1400': 366, '1401': 367, '1402': 368, '1403': 369, '1404': 370, '1405': 371, '1406': 372, '1408': 373, '1409': 374, '141': 375, '1410': 376, '1411': 377, '1412': 378, '1413': 379, '1415': 380, '1418': 381, '142': 382, '1420': 383, '1422': 384, '1423': 385, '1424': 386, '1425': 387, '1426': 388, '1427': 389, '1428': 390, '1429': 391, '143': 392, '1430': 393, '1431': 394, '1432': 395, '1434': 396, '1435': 397, '1437': 398, '1439': 399, '144': 400, '1441': 401, '1442': 402, '1444': 403, '1445': 404, '1446': 405, '1447': 406, '1449': 407, '145': 408, '1451': 409, '1452': 410, '1453': 411, '1454': 412, '1456': 413, '1457': 414, '1458': 415, '1459': 416, '146': 417, '1461': 418, '1462': 419, '1463': 420, '1464': 421, '1465': 422, '1468': 423, '147': 424, '1470': 425, '1471': 426, '1472': 427, '1473': 428, '1477': 429, '1478': 430, '148': 431, '1480': 432, '1481': 433, '1484': 434, '1485': 435, '1487': 436, '1488': 437, '1489': 438, '149': 439, '1490': 440, '1491': 441, '1492': 442, '1493': 443, '1494': 444, '1495': 445, '1496': 446, '1497': 447, '1499': 448, '15': 449, '150': 450, '1500': 451, '1502': 452, '1503': 453, '1504': 454, '1505': 455, '1506': 456, '1507': 457, '1508': 458, '1509': 459, '151': 460, '1511': 461, '1513': 462, '1514': 463, '1515': 464, '1516': 465, '1517': 466, '1519': 467, '152': 468, '1520': 469, '1521': 470, '1523': 471, '1524': 472, '1525': 473, '1527': 474, '1528': 475, '1530': 476, '1531': 477, '1532': 478, '1533': 479, '1534': 480, '1535': 481, '1536': 482, '1537': 483, '154': 484, '1540': 485, '1543': 486, '1544': 487, '1545': 488, '1546': 489, '1547': 490, '1548': 491, '1549': 492, '155': 493, '1550': 494, '1551': 495, '1552': 496, '1553': 497, '1554': 498, '1555': 499, '1556': 500, '1557': 501, '1558': 502, '1559': 503, '1561': 504, '1562': 505, '1565': 506, '1566': 507, '1567': 508, '1568': 509, '1569': 510, '157': 511, '1570': 512, '1571': 513, '1572': 514, '1573': 515, '1574': 516, '1575': 517, '1576': 518, '1578': 519, '158': 520, '1581': 521, '1582': 522, '1584': 523, '1586': 524, '1587': 525, '1589': 526, '159': 527, '1590': 528, '1592': 529, '1593': 530, '1594': 531, '1595': 532, '1596': 533, '1597': 534, '1598': 535, '16': 536, '160': 537, '1601': 538, '1602': 539, '1603': 540, '1604': 541, '1606': 542, '1607': 543, '1608': 544, '161': 545, '1610': 546, '1611': 547, '1612': 548, '1614': 549, '1615': 550, '1617': 551, '1618': 552, '1619': 553, '1622': 554, '1624': 555, '1626': 556, '1627': 557, '163': 558, '1630': 559, '1631': 560, '1633': 561, '1634': 562, '1636': 563, '1637': 564, '1638': 565, '1639': 566, '164': 567, '1640': 568, '1641': 569, '1642': 570, '1643': 571, '1644': 572, '1645': 573, '1646': 574, '1647': 575, '1648': 576, '1649': 577, '165': 578, '1651': 579, '1654': 580, '1655': 581, '1656': 582, '1657': 583, '1658': 584, '1659': 585, '166': 586, '1660': 587, '1661': 588, '1662': 589, '1663': 590, '1664': 591, '1666': 592, '1667': 593, '1669': 594, '167': 595, '1670': 596, '1671': 597, '1672': 598, '1673': 599, '1674': 600, '1675': 601, '1676': 602, '1677': 603, '1678': 604, '1679': 605, '1680': 606, '1681': 607, '1683': 608, '1684': 609, '1686': 610, '1688': 611, '1689': 612, '1690': 613, '1691': 614, '1692': 615, '1694': 616, '1697': 617, '1698': 618, '1699': 619, '17': 620, '1700': 621, '1701': 622, '1703': 623, '1704': 624, '1705': 625, '1706': 626, '1707': 627, '1708': 628, '171': 629, '1710': 630, '1711': 631, '1713': 632, '1714': 633, '1715': 634, '1716': 635, '1717': 636, '1718': 637, '1719': 638, '172': 639, '1720': 640, '1721': 641, '1722': 642, '1723': 643, '1726': 644, '1727': 645, '173': 646, '1730': 647, '1731': 648, '1732': 649, '1733': 650, '1734': 651, '1735': 652, '1736': 653, '1737': 654, '1738': 655, '1739': 656, '1740': 657, '1741': 658, '1742': 659, '1744': 660, '1745': 661, '1747': 662, '1748': 663, '175': 664, '1750': 665, '1751': 666, '1752': 667, '1753': 668, '1754': 669, '1755': 670, '1756': 671, '1757': 672, '1758': 673, '1759': 674, '176': 675, '1761': 676, '1762': 677, '1763': 678, '1764': 679, '1765': 680, '1767': 681, '1768': 682, '1769': 683, '177': 684, '1770': 685, '1771': 686, '1772': 687, '1773': 688, '1774': 689, '1775': 690, '1776': 691, '1777': 692, '1778': 693, '1779': 694, '178': 695, '1780': 696, '1781': 697, '1782': 698, '1783': 699, '1784': 700, '1785': 701, '1787': 702, '1789': 703, '1790': 704, '1791': 705, '1793': 706, '1795': 707, '1796': 708, '1797': 709, '1798': 710, '1799': 711, '18': 712, '180': 713, '1800': 714, '1803': 715, '1804': 716, '1805': 717, '1807': 718, '1809': 719, '1811': 720, '1812': 721, '1813': 722, '1815': 723, '1816': 724, '1817': 725, '1818': 726, '1819': 727, '182': 728, '1822': 729, '1823': 730, '1824': 731, '1825': 732, '1829': 733, '183': 734, '1830': 735, '1832': 736, '1833': 737, '1836': 738, '1837': 739, '1838': 740, '1839': 741, '184': 742, '1840': 743, '1841': 744, '1842': 745, '1843': 746, '1845': 747, '1847': 748, '1849': 749, '185': 750, '1850': 751, '1851': 752, '1852': 753, '1853': 754, '1854': 755, '1855': 756, '1857': 757, '1858': 758, '1859': 759, '186': 760, '1860': 761, '1861': 762, '1862': 763, '1863': 764, '1864': 765, '1865': 766, '1866': 767, '1867': 768, '1868': 769, '1869': 770, '187': 771, '1870': 772, '1871': 773, '1872': 774, '1873': 775, '1875': 776, '1876': 777, '1878': 778, '1879': 779, '188': 780, '1880': 781, '1881': 782, '1882': 783, '1883': 784, '1885': 785, '1886': 786, '1887': 787, '1888': 788, '1889': 789, '1890': 790, '1891': 791, '1892': 792, '1893': 793, '1895': 794, '1897': 795, '1898': 796, '1899': 797, '19': 798, '190': 799, '1900': 800, '1901': 801, '1904': 802, '1905': 803, '1906': 804, '1908': 805, '1909': 806, '191': 807, '1910': 808, '1911': 809, '1912': 810, '1913': 811, '1914': 812, '1915': 813, '1919': 814, '1920': 815, '1921': 816, '1922': 817, '1923': 818, '1924': 819, '1926': 820, '1927': 821, '1928': 822, '1929': 823, '1930': 824, '1931': 825, '1932': 826, '1934': 827, '1936': 828, '1937': 829, '1938': 830, '1939': 831, '194': 832, '1940': 833, '1942': 834, '1943': 835, '1944': 836, '1946': 837, '1947': 838, '1949': 839, '195': 840, '1952': 841, '1953': 842, '1954': 843, '1956': 844, '1957': 845, '1958': 846, '1959': 847, '196': 848, '1960': 849, '1961': 850, '1965': 851, '1966': 852, '1969': 853, '197': 854, '1971': 855, '1972': 856, '1973': 857, '1975': 858, '1978': 859, '1979': 860, '1980': 861, '1981': 862, '1982': 863, '1983': 864, '1984': 865, '1985': 866, '1987': 867, '1989': 868, '199': 869, '1990': 870, '1993': 871, '1994': 872, '1995': 873, '1996': 874, '1997': 875, '1998': 876, '2': 877, '20': 878, '2000': 879, '2001': 880, '2003': 881, '2004': 882, '2007': 883, '2008': 884, '2009': 885, '201': 886, '2010': 887, '2011': 888, '2012': 889, '2013': 890, '2014': 891, '2015': 892, '2016': 893, '2017': 894, '2018': 895, '2019': 896, '2020': 897, '2021': 898, '2022': 899, '2023': 900, '2024': 901, '2025': 902, '2026': 903, '2027': 904, '2029': 905, '203': 906, '2030': 907, '2031': 908, '2032': 909, '2033': 910, '2034': 911, '2035': 912, '2036': 913, '2037': 914, '2039': 915, '204': 916, '2040': 917, '2041': 918, '2042': 919, '2043': 920, '2044': 921, '2046': 922, '2047': 923, '2048': 924, '2052': 925, '2053': 926, '2054': 927, '2055': 928, '2056': 929, '2057': 930, '2058': 931, '2059': 932, '206': 933, '2060': 934, '2062': 935, '2063': 936, '2064': 937, '2067': 938, '2068': 939, '207': 940, '2070': 941, '2071': 942, '2072': 943, '2073': 944, '2074': 945, '2075': 946, '2077': 947, '2079': 948, '208': 949, '2080': 950, '2082': 951, '2083': 952, '2084': 953, '2085': 954, '2087': 955, '2089': 956, '209': 957, '2090': 958, '2092': 959, '2093': 960, '2095': 961, '2097': 962, '2098': 963, '2099': 964, '21': 965, '210': 966, '2100': 967, '2101': 968, '2102': 969, '2103': 970, '2104': 971, '2105': 972, '2106': 973, '2107': 974, '2108': 975, '2109': 976, '2110': 977, '2111': 978, '2113': 979, '2115': 980, '2116': 981, '2117': 982, '2118': 983, '2119': 984, '212': 985, '2120': 986, '2121': 987, '2122': 988, '2123': 989, '2124': 990, '2125': 991, '2127': 992, '2128': 993, '213': 994, '2130': 995, '2131': 996, '2132': 997, '2133': 998, '2134': 999, '2135': 1000, '2137': 1001, '2138': 1002, '2139': 1003, '214': 1004, '2140': 1005, '2141': 1006, '2142': 1007, '2144': 1008, '2145': 1009, '2146': 1010, '2147': 1011, '2148': 1012, '2149': 1013, '215': 1014, '2150': 1015, '2151': 1016, '2152': 1017, '2153': 1018, '2154': 1019, '2155': 1020, '2156': 1021, '2157': 1022, '2158': 1023, '2159': 1024, '216': 1025, '2160': 1026, '2161': 1027, '2162': 1028, '2163': 1029, '2165': 1030, '2166': 1031, '2167': 1032, '2168': 1033, '217': 1034, '2171': 1035, '2172': 1036, '2173': 1037, '2175': 1038, '2176': 1039, '2177': 1040, '2178': 1041, '2179': 1042, '218': 1043, '2180': 1044, '2181': 1045, '2182': 1046, '2183': 1047, '2184': 1048, '2185': 1049, '2186': 1050, '2187': 1051, '2188': 1052, '219': 1053, '2190': 1054, '2191': 1055, '2192': 1056, '2193': 1057, '2194': 1058, '2195': 1059, '2198': 1060, '2199': 1061, '22': 1062, '220': 1063, '2200': 1064, '2201': 1065, '2202': 1066, '2204': 1067, '2205': 1068, '2206': 1069, '2207': 1070, '2208': 1071, '2209': 1072, '221': 1073, '2210': 1074, '2213': 1075, '2214': 1076, '2215': 1077, '2216': 1078, '2217': 1079, '2218': 1080, '222': 1081, '2220': 1082, '2221': 1083, '2222': 1084, '2223': 1085, '2225': 1086, '2226': 1087, '2227': 1088, '2228': 1089, '2229': 1090, '223': 1091, '2230': 1092, '2231': 1093, '2232': 1094, '2233': 1095, '2234': 1096, '2235': 1097, '2236': 1098, '2238': 1099, '2239': 1100, '2240': 1101, '2241': 1102, '2243': 1103, '2244': 1104, '2245': 1105, '2246': 1106, '2247': 1107, '2248': 1108, '2249': 1109, '225': 1110, '2250': 1111, '2251': 1112, '2252': 1113, '2253': 1114, '2254': 1115, '2255': 1116, '2257': 1117, '2258': 1118, '226': 1119, '2260': 1120, '2261': 1121, '2262': 1122, '2264': 1123, '2265': 1124, '2267': 1125, '2268': 1126, '2269': 1127, '2270': 1128, '2272': 1129, '2273': 1130, '2274': 1131, '2275': 1132, '2276': 1133, '2277': 1134, '2278': 1135, '228': 1136, '2280': 1137, '2281': 1138, '2283': 1139, '2284': 1140, '2285': 1141, '2286': 1142, '2287': 1143, '2288': 1144, '2289': 1145, '229': 1146, '2290': 1147, '2292': 1148, '2295': 1149, '2296': 1150, '2297': 1151, '2298': 1152, '2299': 1153, '23': 1154, '230': 1155, '2300': 1156, '2301': 1157, '2302': 1158, '2303': 1159, '2305': 1160, '2306': 1161, '2307': 1162, '2308': 1163, '2309': 1164, '2311': 1165, '2312': 1166, '2313': 1167, '2314': 1168, '2316': 1169, '2317': 1170, '2318': 1171, '2319': 1172, '232': 1173, '2320': 1174, '2321': 1175, '2323': 1176, '2324': 1177, '2325': 1178, '2326': 1179, '2327': 1180, '2329': 1181, '233': 1182, '2330': 1183, '2332': 1184, '2333': 1185, '2336': 1186, '2337': 1187, '2340': 1188, '2342': 1189, '2343': 1190, '2345': 1191, '2347': 1192, '2348': 1193, '2349': 1194, '235': 1195, '2350': 1196, '2351': 1197, '2352': 1198, '2353': 1199, '2354': 1200, '2355': 1201, '2356': 1202, '2358': 1203, '236': 1204, '2360': 1205, '2362': 1206, '2363': 1207, '2364': 1208, '2367': 1209, '2368': 1210, '2369': 1211, '237': 1212, '2370': 1213, '2372': 1214, '2373': 1215, '2375': 1216, '2376': 1217, '2378': 1218, '238': 1219, '2380': 1220, '2381': 1221, '2382': 1222, '2383': 1223, '2384': 1224, '2385': 1225, '2386': 1226, '2387': 1227, '2388': 1228, '2389': 1229, '239': 1230, '2391': 1231, '2392': 1232, '2393': 1233, '2394': 1234, '2395': 1235, '2397': 1236, '2398': 1237, '2399': 1238, '240': 1239, '2400': 1240, '2401': 1241, '2402': 1242, '2403': 1243, '2404': 1244, '2406': 1245, '2407': 1246, '2408': 1247, '2409': 1248, '241': 1249, '2410': 1250, '2411': 1251, '2412': 1252, '2413': 1253, '2414': 1254, '2415': 1255, '2416': 1256, '2417': 1257, '2419': 1258, '242': 1259, '2420': 1260, '2421': 1261, '2423': 1262, '2424': 1263, '2425': 1264, '2426': 1265, '2428': 1266, '2429': 1267, '243': 1268, '2431': 1269, '2433': 1270, '2434': 1271, '2435': 1272, '2436': 1273, '2437': 1274, '2438': 1275, '2439': 1276, '244': 1277, '2440': 1278, '2441': 1279, '2442': 1280, '2443': 1281, '2445': 1282, '2446': 1283, '2447': 1284, '245': 1285, '2450': 1286, '2451': 1287, '2454': 1288, '2455': 1289, '2456': 1290, '2459': 1291, '246': 1292, '2460': 1293, '2462': 1294, '2463': 1295, '2464': 1296, '2466': 1297, '2467': 1298, '2468': 1299, '2469': 1300, '247': 1301, '2470': 1302, '2471': 1303, '2472': 1304, '2473': 1305, '2474': 1306, '2476': 1307, '2477': 1308, '2478': 1309, '2479': 1310, '248': 1311, '2480': 1312, '2481': 1313, '2482': 1314, '2486': 1315, '2487': 1316, '2488': 1317, '2489': 1318, '249': 1319, '2490': 1320, '2491': 1321, '2492': 1322, '2493': 1323, '2494': 1324, '2495': 1325, '2497': 1326, '2498': 1327, '2499': 1328, '250': 1329, '2500': 1330, '2501': 1331, '2502': 1332, '2503': 1333, '2504': 1334, '2505': 1335, '2507': 1336, '2509': 1337, '251': 1338, '2510': 1339, '2511': 1340, '2512': 1341, '2513': 1342, '2514': 1343, '2515': 1344, '2517': 1345, '2518': 1346, '2519': 1347, '2520': 1348, '2521': 1349, '2522': 1350, '2523': 1351, '2524': 1352, '2525': 1353, '2526': 1354, '2527': 1355, '2528': 1356, '2529': 1357, '253': 1358, '2530': 1359, '2531': 1360, '2532': 1361, '2533': 1362, '2534': 1363, '2535': 1364, '2536': 1365, '2537': 1366, '2538': 1367, '2540': 1368, '2541': 1369, '2543': 1370, '2544': 1371, '2546': 1372, '2547': 1373, '2548': 1374, '2549': 1375, '2550': 1376, '2551': 1377, '2552': 1378, '2553': 1379, '2554': 1380, '2556': 1381, '2557': 1382, '2558': 1383, '2559': 1384, '256': 1385, '2560': 1386, '2561': 1387, '2562': 1388, '2563': 1389, '2564': 1390, '2565': 1391, '2567': 1392, '2569': 1393, '257': 1394, '2570': 1395, '2571': 1396, '2572': 1397, '2574': 1398, '2575': 1399, '2576': 1400, '2578': 1401, '2580': 1402, '2581': 1403, '2582': 1404, '2583': 1405, '2584': 1406, '2585': 1407, '2586': 1408, '2589': 1409, '259': 1410, '2591': 1411, '2592': 1412, '2593': 1413, '2594': 1414, '2596': 1415, '2597': 1416, '2598': 1417, '2599': 1418, '26': 1419, '260': 1420, '2600': 1421, '2602': 1422, '2604': 1423, '2605': 1424, '2606': 1425, '2608': 1426, '2609': 1427, '261': 1428, '2610': 1429, '2611': 1430, '2612': 1431, '2613': 1432, '2614': 1433, '2615': 1434, '2616': 1435, '2617': 1436, '2618': 1437, '2619': 1438, '262': 1439, '2621': 1440, '2622': 1441, '2624': 1442, '2628': 1443, '2629': 1444, '263': 1445, '2631': 1446, '2634': 1447, '2635': 1448, '2637': 1449, '2639': 1450, '264': 1451, '2640': 1452, '2641': 1453, '2642': 1454, '2643': 1455, '2645': 1456, '2646': 1457, '2647': 1458, '2648': 1459, '2649': 1460, '265': 1461, '2650': 1462, '2651': 1463, '2652': 1464, '2653': 1465, '2654': 1466, '2655': 1467, '2656': 1468, '2657': 1469, '2658': 1470, '2659': 1471, '2660': 1472, '2663': 1473, '2664': 1474, '2665': 1475, '2666': 1476, '2667': 1477, '2668': 1478, '2669': 1479, '267': 1480, '2670': 1481, '2671': 1482, '2672': 1483, '2674': 1484, '2675': 1485, '2676': 1486, '2677': 1487, '2678': 1488, '268': 1489, '2680': 1490, '2681': 1491, '2682': 1492, '2684': 1493, '2685': 1494, '2686': 1495, '2687': 1496, '2688': 1497, '2689': 1498, '269': 1499, '2690': 1500, '2692': 1501, '2694': 1502, '2695': 1503, '2696': 1504, '2697': 1505, '2698': 1506, '27': 1507, '270': 1508, '2700': 1509, '2701': 1510, '2702': 1511, '2704': 1512, '2705': 1513, '2707': 1514, '2708': 1515, '2709': 1516, '271': 1517, '2710': 1518, '2711': 1519, '2712': 1520, '2713': 1521, '2714': 1522, '2715': 1523, '2716': 1524, '2717': 1525, '2718': 1526, '2719': 1527, '2721': 1528, '2722': 1529, '2723': 1530, '2724': 1531, '2726': 1532, '2728': 1533, '2730': 1534, '2731': 1535, '2733': 1536, '2734': 1537, '2735': 1538, '2736': 1539, '2738': 1540, '2739': 1541, '274': 1542, '2740': 1543, '2741': 1544, '2742': 1545, '2743': 1546, '2746': 1547, '2747': 1548, '2748': 1549, '2749': 1550, '275': 1551, '2750': 1552, '2752': 1553, '2753': 1554, '2754': 1555, '2755': 1556, '2756': 1557, '2757': 1558, '2758': 1559, '2759': 1560, '2760': 1561, '2761': 1562, '2762': 1563, '2763': 1564, '2765': 1565, '2766': 1566, '2767': 1567, '2768': 1568, '277': 1569, '2770': 1570, '2772': 1571, '2773': 1572, '2774': 1573, '2775': 1574, '2776': 1575, '2777': 1576, '2778': 1577, '278': 1578, '2780': 1579, '2781': 1580, '2782': 1581, '2783': 1582, '2784': 1583, '2785': 1584, '2786': 1585, '2787': 1586, '2788': 1587, '2789': 1588, '279': 1589, '2790': 1590, '2791': 1591, '2792': 1592, '2793': 1593, '2794': 1594, '2795': 1595, '2796': 1596, '2797': 1597, '2798': 1598, '2799': 1599, '28': 1600, '280': 1601, '2800': 1602, '2801': 1603, '2802': 1604, '2803': 1605, '2804': 1606, '2805': 1607, '2807': 1608, '2808': 1609, '2809': 1610, '281': 1611, '2810': 1612, '2811': 1613, '2812': 1614, '2813': 1615, '2814': 1616, '2816': 1617, '2818': 1618, '2819': 1619, '282': 1620, '2820': 1621, '2821': 1622, '2822': 1623, '2823': 1624, '2824': 1625, '2825': 1626, '2826': 1627, '2827': 1628, '2828': 1629, '2829': 1630, '283': 1631, '2830': 1632, '2831': 1633, '2832': 1634, '2833': 1635, '2834': 1636, '2836': 1637, '2837': 1638, '2839': 1639, '284': 1640, '2842': 1641, '2843': 1642, '2844': 1643, '2847': 1644, '2849': 1645, '285': 1646, '2850': 1647, '2851': 1648, '2852': 1649, '2853': 1650, '2855': 1651, '2856': 1652, '2857': 1653, '2858': 1654, '2859': 1655, '286': 1656, '2861': 1657, '2863': 1658, '2864': 1659, '2865': 1660, '2868': 1661, '2869': 1662, '287': 1663, '2870': 1664, '2874': 1665, '2876': 1666, '2877': 1667, '2878': 1668, '2879': 1669, '2880': 1670, '2883': 1671, '2886': 1672, '2888': 1673, '2889': 1674, '2890': 1675, '2892': 1676, '2893': 1677, '2894': 1678, '2895': 1679, '2896': 1680, '2897': 1681, '2899': 1682, '29': 1683, '290': 1684, '2900': 1685, '2901': 1686, '2904': 1687, '2905': 1688, '2906': 1689, '2907': 1690, '2908': 1691, '2909': 1692, '291': 1693, '2910': 1694, '2911': 1695, '2912': 1696, '2914': 1697, '2915': 1698, '2916': 1699, '2917': 1700, '292': 1701, '2920': 1702, '2921': 1703, '2922': 1704, '2924': 1705, '2926': 1706, '2927': 1707, '2928': 1708, '2929': 1709, '293': 1710, '2931': 1711, '2932': 1712, '2933': 1713, '2934': 1714, '2936': 1715, '2937': 1716, '2938': 1717, '2939': 1718, '2940': 1719, '2941': 1720, '2942': 1721, '2945': 1722, '2946': 1723, '2947': 1724, '2948': 1725, '2949': 1726, '295': 1727, '2950': 1728, '2951': 1729, '2952': 1730, '2953': 1731, '2954': 1732, '2955': 1733, '2956': 1734, '2957': 1735, '2958': 1736, '2959': 1737, '296': 1738, '2960': 1739, '2961': 1740, '2962': 1741, '2964': 1742, '2965': 1743, '2966': 1744, '2967': 1745, '2968': 1746, '2969': 1747, '297': 1748, '2970': 1749, '2971': 1750, '2972': 1751, '2973': 1752, '2974': 1753, '2975': 1754, '2976': 1755, '2978': 1756, '2979': 1757, '298': 1758, '2980': 1759, '2981': 1760, '2982': 1761, '2983': 1762, '2985': 1763, '2986': 1764, '2987': 1765, '2988': 1766, '2989': 1767, '299': 1768, '2991': 1769, '2993': 1770, '2995': 1771, '2996': 1772, '2998': 1773, '2999': 1774, '3': 1775, '300': 1776, '3001': 1777, '3002': 1778, '3004': 1779, '3005': 1780, '3007': 1781, '3008': 1782, '3009': 1783, '3010': 1784, '3011': 1785, '3012': 1786, '3013': 1787, '3014': 1788, '3018': 1789, '3019': 1790, '302': 1791, '3021': 1792, '3022': 1793, '3024': 1794, '3025': 1795, '3027': 1796, '3028': 1797, '303': 1798, '3030': 1799, '3031': 1800, '3032': 1801, '3033': 1802, '3035': 1803, '3036': 1804, '3037': 1805, '3038': 1806, '3039': 1807, '304': 1808, '3041': 1809, '3043': 1810, '3044': 1811, '3045': 1812, '3046': 1813, '3047': 1814, '3048': 1815, '3049': 1816, '305': 1817, '3050': 1818, '3051': 1819, '3053': 1820, '3054': 1821, '3055': 1822, '3056': 1823, '3057': 1824, '306': 1825, '3060': 1826, '3061': 1827, '3062': 1828, '3064': 1829, '3065': 1830, '3068': 1831, '3069': 1832, '307': 1833, '3070': 1834, '3071': 1835, '3072': 1836, '3073': 1837, '3074': 1838, '3075': 1839, '3076': 1840, '3077': 1841, '3079': 1842, '308': 1843, '3080': 1844, '3081': 1845, '3082': 1846, '3085': 1847, '3086': 1848, '3087': 1849, '3088': 1850, '3089': 1851, '309': 1852, '3090': 1853, '3091': 1854, '3092': 1855, '3093': 1856, '3095': 1857, '3096': 1858, '3097': 1859, '3098': 1860, '3099': 1861, '31': 1862, '310': 1863, '3100': 1864, '3101': 1865, '3102': 1866, '3103': 1867, '3104': 1868, '3105': 1869, '3106': 1870, '3107': 1871, '3108': 1872, '3109': 1873, '311': 1874, '3111': 1875, '3112': 1876, '3113': 1877, '3114': 1878, '3115': 1879, '3116': 1880, '3117': 1881, '3118': 1882, '3119': 1883, '312': 1884, '3120': 1885, '3121': 1886, '3122': 1887, '3123': 1888, '3124': 1889, '3125': 1890, '3126': 1891, '3128': 1892, '3129': 1893, '313': 1894, '3131': 1895, '3132': 1896, '3133': 1897, '3134': 1898, '3135': 1899, '3137': 1900, '3138': 1901, '3139': 1902, '3140': 1903, '3141': 1904, '3142': 1905, '3143': 1906, '3145': 1907, '3146': 1908, '3148': 1909, '3149': 1910, '3150': 1911, '3153': 1912, '3154': 1913, '3155': 1914, '3156': 1915, '3158': 1916, '3159': 1917, '3160': 1918, '3161': 1919, '3162': 1920, '3163': 1921, '3164': 1922, '3165': 1923, '3166': 1924, '3167': 1925, '3168': 1926, '3169': 1927, '317': 1928, '3170': 1929, '3172': 1930, '3173': 1931, '3174': 1932, '3175': 1933, '3178': 1934, '3179': 1935, '318': 1936, '3180': 1937, '3181': 1938, '3184': 1939, '3185': 1940, '3186': 1941, '3187': 1942, '3188': 1943, '3189': 1944, '319': 1945, '3190': 1946, '3191': 1947, '3192': 1948, '3195': 1949, '3197': 1950, '3198': 1951, '3199': 1952, '32': 1953, '320': 1954, '3200': 1955, '3202': 1956, '3203': 1957, '3205': 1958, '3206': 1959, '3207': 1960, '3208': 1961, '3209': 1962, '321': 1963, '3210': 1964, '3211': 1965, '3212': 1966, '3213': 1967, '3214': 1968, '3215': 1969, '3217': 1970, '3218': 1971, '3219': 1972, '322': 1973, '3220': 1974, '3221': 1975, '3222': 1976, '3223': 1977, '3224': 1978, '3227': 1979, '3228': 1980, '3229': 1981, '3230': 1982, '3232': 1983, '3233': 1984, '3234': 1985, '3235': 1986, '3236': 1987, '3238': 1988, '324': 1989, '3240': 1990, '3241': 1991, '3243': 1992, '3245': 1993, '3246': 1994, '3247': 1995, '3248': 1996, '3249': 1997, '325': 1998, '3250': 1999, '3251': 2000, '3252': 2001, '3253': 2002, '3254': 2003, '3255': 2004, '3256': 2005, '3257': 2006, '3258': 2007, '3259': 2008, '326': 2009, '3261': 2010, '3262': 2011, '3263': 2012, '3264': 2013, '3265': 2014, '3266': 2015, '3267': 2016, '3268': 2017, '327': 2018, '3270': 2019, '3271': 2020, '3272': 2021, '3273': 2022, '3274': 2023, '3275': 2024, '3276': 2025, '3278': 2026, '3279': 2027, '328': 2028, '3281': 2029, '3282': 2030, '3283': 2031, '3284': 2032, '3285': 2033, '3286': 2034, '3287': 2035, '3288': 2036, '3289': 2037, '329': 2038, '3290': 2039, '3291': 2040, '3292': 2041, '3293': 2042, '3294': 2043, '3295': 2044, '3296': 2045, '3297': 2046, '3298': 2047, '3299': 2048, '33': 2049, '330': 2050, '3300': 2051, '3301': 2052, '3302': 2053, '3303': 2054, '3304': 2055, '3305': 2056, '3306': 2057, '3308': 2058, '331': 2059, '3310': 2060, '3313': 2061, '3315': 2062, '3317': 2063, '3318': 2064, '3319': 2065, '3320': 2066, '3321': 2067, '3322': 2068, '3323': 2069, '3325': 2070, '3326': 2071, '3327': 2072, '3328': 2073, '3329': 2074, '333': 2075, '3330': 2076, '3334': 2077, '3335': 2078, '3336': 2079, '3337': 2080, '3339': 2081, '334': 2082, '3340': 2083, '3341': 2084, '3343': 2085, '3344': 2086, '3345': 2087, '3346': 2088, '3347': 2089, '3348': 2090, '3349': 2091, '335': 2092, '3350': 2093, '3353': 2094, '3354': 2095, '3355': 2096, '3356': 2097, '3357': 2098, '3359': 2099, '336': 2100, '3360': 2101, '3361': 2102, '3362': 2103, '3363': 2104, '3365': 2105, '3366': 2106, '3367': 2107, '3368': 2108, '3369': 2109, '337': 2110, '3370': 2111, '3371': 2112, '3372': 2113, '3373': 2114, '3374': 2115, '3375': 2116, '3376': 2117, '3380': 2118, '3381': 2119, '3382': 2120, '3384': 2121, '3385': 2122, '3386': 2123, '3387': 2124, '3388': 2125, '3389': 2126, '339': 2127, '3390': 2128, '3391': 2129, '3392': 2130, '3393': 2131, '3394': 2132, '3395': 2133, '3397': 2134, '3398': 2135, '34': 2136, '340': 2137, '3400': 2138, '3401': 2139, '3402': 2140, '3403': 2141, '3404': 2142, '3405': 2143, '3406': 2144, '3407': 2145, '3409': 2146, '3410': 2147, '3411': 2148, '3412': 2149, '3414': 2150, '3415': 2151, '3416': 2152, '3417': 2153, '3419': 2154, '342': 2155, '3420': 2156, '3421': 2157, '3422': 2158, '3423': 2159, '3424': 2160, '3425': 2161, '3426': 2162, '3427': 2163, '3428': 2164, '3429': 2165, '343': 2166, '3431': 2167, '3433': 2168, '3434': 2169, '3435': 2170, '3436': 2171, '3437': 2172, '3438': 2173, '344': 2174, '3442': 2175, '3443': 2176, '3445': 2177, '3446': 2178, '3447': 2179, '3448': 2180, '3449': 2181, '345': 2182, '3450': 2183, '3451': 2184, '3452': 2185, '3453': 2186, '3454': 2187, '3455': 2188, '3457': 2189, '3458': 2190, '3459': 2191, '3460': 2192, '3461': 2193, '3462': 2194, '3464': 2195, '3465': 2196, '3466': 2197, '3467': 2198, '3468': 2199, '3469': 2200, '347': 2201, '3470': 2202, '3471': 2203, '3472': 2204, '3474': 2205, '3475': 2206, '3477': 2207, '3478': 2208, '3479': 2209, '348': 2210, '3480': 2211, '3481': 2212, '3482': 2213, '3484': 2214, '3485': 2215, '3486': 2216, '3487': 2217, '3488': 2218, '3489': 2219, '349': 2220, '3490': 2221, '3491': 2222, '3492': 2223, '3493': 2224, '3494': 2225, '3495': 2226, '3497': 2227, '3499': 2228, '350': 2229, '3500': 2230, '3502': 2231, '3503': 2232, '3505': 2233, '3506': 2234, '3507': 2235, '3508': 2236, '3509': 2237, '351': 2238, '3510': 2239, '3511': 2240, '3512': 2241, '3513': 2242, '3514': 2243, '3515': 2244, '3516': 2245, '3517': 2246, '3518': 2247, '352': 2248, '3521': 2249, '3523': 2250, '3524': 2251, '3525': 2252, '3526': 2253, '3527': 2254, '3529': 2255, '353': 2256, '3530': 2257, '3531': 2258, '3532': 2259, '3533': 2260, '3534': 2261, '3537': 2262, '3539': 2263, '354': 2264, '3540': 2265, '3541': 2266, '3542': 2267, '3543': 2268, '3544': 2269, '3546': 2270, '3548': 2271, '3549': 2272, '355': 2273, '3550': 2274, '3551': 2275, '3552': 2276, '3553': 2277, '3554': 2278, '3555': 2279, '3556': 2280, '3558': 2281, '3559': 2282, '3560': 2283, '3561': 2284, '3562': 2285, '3563': 2286, '3564': 2287, '3565': 2288, '3566': 2289, '3567': 2290, '3568': 2291, '3569': 2292, '3570': 2293, '3571': 2294, '3572': 2295, '3573': 2296, '3574': 2297, '3576': 2298, '3577': 2299, '3578': 2300, '3579': 2301, '358': 2302, '3580': 2303, '3581': 2304, '3583': 2305, '3584': 2306, '3585': 2307, '3586': 2308, '3587': 2309, '3588': 2310, '3589': 2311, '359': 2312, '3590': 2313, '3591': 2314, '3593': 2315, '3594': 2316, '3595': 2317, '3596': 2318, '3598': 2319, '3599': 2320, '36': 2321, '360': 2322, '3600': 2323, '3601': 2324, '3602': 2325, '3603': 2326, '3604': 2327, '3605': 2328, '3606': 2329, '3607': 2330, '3609': 2331, '361': 2332, '3610': 2333, '3611': 2334, '3612': 2335, '3613': 2336, '3615': 2337, '3616': 2338, '3617': 2339, '3618': 2340, '3619': 2341, '362': 2342, '3620': 2343, '3621': 2344, '3623': 2345, '3624': 2346, '3625': 2347, '3626': 2348, '3627': 2349, '3628': 2350, '3629': 2351, '363': 2352, '3631': 2353, '3633': 2354, '3634': 2355, '3635': 2356, '3636': 2357, '3638': 2358, '3639': 2359, '3640': 2360, '3643': 2361, '3644': 2362, '3645': 2363, '3646': 2364, '3647': 2365, '3648': 2366, '365': 2367, '3650': 2368, '3651': 2369, '3652': 2370, '3653': 2371, '3654': 2372, '3655': 2373, '3656': 2374, '3657': 2375, '3659': 2376, '366': 2377, '3660': 2378, '3661': 2379, '3662': 2380, '3663': 2381, '3664': 2382, '3665': 2383, '3666': 2384, '3667': 2385, '3668': 2386, '3669': 2387, '3670': 2388, '3671': 2389, '3672': 2390, '3673': 2391, '3674': 2392, '3675': 2393, '3678': 2394, '368': 2395, '3680': 2396, '3681': 2397, '3683': 2398, '3686': 2399, '3688': 2400, '3689': 2401, '369': 2402, '3690': 2403, '3691': 2404, '3692': 2405, '3693': 2406, '3694': 2407, '3696': 2408, '3697': 2409, '3698': 2410, '37': 2411, '3700': 2412, '3701': 2413, '3702': 2414, '3703': 2415, '3704': 2416, '3705': 2417, '3706': 2418, '3707': 2419, '3708': 2420, '3709': 2421, '371': 2422, '3711': 2423, '3712': 2424, '3713': 2425, '3715': 2426, '3716': 2427, '3717': 2428, '3718': 2429, '372': 2430, '3721': 2431, '3722': 2432, '3723': 2433, '3724': 2434, '3725': 2435, '3727': 2436, '3729': 2437, '373': 2438, '3731': 2439, '3732': 2440, '3733': 2441, '3734': 2442, '3735': 2443, '3737': 2444, '3738': 2445, '3739': 2446, '374': 2447, '3740': 2448, '3742': 2449, '3743': 2450, '3744': 2451, '3745': 2452, '3746': 2453, '3747': 2454, '3748': 2455, '3749': 2456, '375': 2457, '3752': 2458, '3753': 2459, '3756': 2460, '3757': 2461, '3758': 2462, '3759': 2463, '376': 2464, '3760': 2465, '3761': 2466, '3762': 2467, '3763': 2468, '3764': 2469, '3765': 2470, '3767': 2471, '3769': 2472, '377': 2473, '3770': 2474, '3772': 2475, '3773': 2476, '3774': 2477, '3775': 2478, '3776': 2479, '3777': 2480, '3779': 2481, '378': 2482, '3781': 2483, '3782': 2484, '3785': 2485, '3786': 2486, '3787': 2487, '3788': 2488, '3789': 2489, '3790': 2490, '3791': 2491, '3792': 2492, '3793': 2493, '3794': 2494, '3795': 2495, '3797': 2496, '3798': 2497, '380': 2498, '3800': 2499, '3801': 2500, '3804': 2501, '3805': 2502, '3806': 2503, '3807': 2504, '3808': 2505, '3809': 2506, '381': 2507, '3811': 2508, '3812': 2509, '3815': 2510, '3817': 2511, '3818': 2512, '3819': 2513, '382': 2514, '3820': 2515, '3821': 2516, '3822': 2517, '3823': 2518, '3824': 2519, '3825': 2520, '3826': 2521, '3827': 2522, '383': 2523, '3830': 2524, '3831': 2525, '3832': 2526, '3833': 2527, '3834': 2528, '3835': 2529, '3838': 2530, '3839': 2531, '3840': 2532, '3841': 2533, '3843': 2534, '3844': 2535, '3845': 2536, '3846': 2537, '3847': 2538, '3848': 2539, '3849': 2540, '385': 2541, '3850': 2542, '3851': 2543, '3852': 2544, '3854': 2545, '3856': 2546, '3857': 2547, '3858': 2548, '386': 2549, '3860': 2550, '3864': 2551, '3865': 2552, '3866': 2553, '3867': 2554, '3868': 2555, '3869': 2556, '3870': 2557, '3871': 2558, '3872': 2559, '3873': 2560, '3874': 2561, '3875': 2562, '3876': 2563, '3877': 2564, '3878': 2565, '388': 2566, '3880': 2567, '3881': 2568, '3882': 2569, '3883': 2570, '3884': 2571, '3885': 2572, '3887': 2573, '3888': 2574, '3890': 2575, '3892': 2576, '3893': 2577, '3894': 2578, '3895': 2579, '3896': 2580, '3897': 2581, '3898': 2582, '3899': 2583, '390': 2584, '3900': 2585, '3901': 2586, '3904': 2587, '3906': 2588, '3907': 2589, '3908': 2590, '3909': 2591, '3910': 2592, '3912': 2593, '3913': 2594, '3914': 2595, '3915': 2596, '3916': 2597, '3917': 2598, '3919': 2599, '392': 2600, '3920': 2601, '3922': 2602, '3924': 2603, '3925': 2604, '3926': 2605, '3927': 2606, '3929': 2607, '393': 2608, '3930': 2609, '3932': 2610, '3933': 2611, '3934': 2612, '3935': 2613, '3936': 2614, '3938': 2615, '3939': 2616, '394': 2617, '3940': 2618, '3941': 2619, '3942': 2620, '3943': 2621, '3944': 2622, '3945': 2623, '3946': 2624, '3947': 2625, '3948': 2626, '3949': 2627, '395': 2628, '3950': 2629, '3951': 2630, '3954': 2631, '3955': 2632, '3956': 2633, '3959': 2634, '396': 2635, '3960': 2636, '3961': 2637, '3962': 2638, '3963': 2639, '3964': 2640, '3965': 2641, '3966': 2642, '3967': 2643, '3968': 2644, '397': 2645, '3970': 2646, '3971': 2647, '3972': 2648, '3973': 2649, '3974': 2650, '3975': 2651, '3976': 2652, '3977': 2653, '3978': 2654, '3979': 2655, '3981': 2656, '3982': 2657, '3983': 2658, '3984': 2659, '3986': 2660, '3987': 2661, '3988': 2662, '3989': 2663, '3991': 2664, '3992': 2665, '3995': 2666, '3997': 2667, '3998': 2668, '3999': 2669, '4': 2670, '40': 2671, '4000': 2672, '4002': 2673, '4003': 2674, '4004': 2675, '4005': 2676, '4006': 2677, '4007': 2678, '4009': 2679, '401': 2680, '4010': 2681, '4011': 2682, '4012': 2683, '4013': 2684, '4014': 2685, '4015': 2686, '4016': 2687, '4017': 2688, '4018': 2689, '4019': 2690, '402': 2691, '4020': 2692, '4023': 2693, '4024': 2694, '4025': 2695, '4026': 2696, '4028': 2697, '403': 2698, '4030': 2699, '4032': 2700, '4034': 2701, '4035': 2702, '4036': 2703, '4037': 2704, '404': 2705, '4042': 2706, '4044': 2707, '4045': 2708, '4046': 2709, '4047': 2710, '4048': 2711, '4049': 2712, '405': 2713, '4050': 2714, '4052': 2715, '4053': 2716, '4054': 2717, '4055': 2718, '4057': 2719, '4059': 2720, '406': 2721, '4062': 2722, '4063': 2723, '4064': 2724, '4065': 2725, '4066': 2726, '4067': 2727, '4068': 2728, '4069': 2729, '4070': 2730, '4072': 2731, '4073': 2732, '4074': 2733, '4075': 2734, '4076': 2735, '4078': 2736, '4079': 2737, '408': 2738, '4080': 2739, '4081': 2740, '4082': 2741, '4083': 2742, '4084': 2743, '4086': 2744, '4087': 2745, '4088': 2746, '4089': 2747, '409': 2748, '4090': 2749, '4092': 2750, '4093': 2751, '4094': 2752, '4095': 2753, '4096': 2754, '4097': 2755, '4098': 2756, '4099': 2757, '410': 2758, '4100': 2759, '4101': 2760, '4102': 2761, '4103': 2762, '4104': 2763, '4105': 2764, '4106': 2765, '4108': 2766, '411': 2767, '4110': 2768, '4111': 2769, '4112': 2770, '4113': 2771, '4114': 2772, '4115': 2773, '4116': 2774, '4117': 2775, '4118': 2776, '4119': 2777, '412': 2778, '4120': 2779, '4121': 2780, '4122': 2781, '4123': 2782, '4124': 2783, '4125': 2784, '4126': 2785, '4127': 2786, '4128': 2787, '4129': 2788, '413': 2789, '4130': 2790, '4131': 2791, '4132': 2792, '4133': 2793, '4134': 2794, '4135': 2795, '4136': 2796, '4137': 2797, '4138': 2798, '4139': 2799, '414': 2800, '4140': 2801, '4141': 2802, '4142': 2803, '4144': 2804, '4145': 2805, '4146': 2806, '4147': 2807, '4148': 2808, '4149': 2809, '4151': 2810, '4152': 2811, '4153': 2812, '4154': 2813, '4155': 2814, '4156': 2815, '4157': 2816, '4158': 2817, '4159': 2818, '4160': 2819, '4161': 2820, '4163': 2821, '4164': 2822, '4165': 2823, '4166': 2824, '4168': 2825, '4169': 2826, '417': 2827, '4170': 2828, '4171': 2829, '4172': 2830, '4173': 2831, '4174': 2832, '4175': 2833, '4176': 2834, '4178': 2835, '4179': 2836, '418': 2837, '4180': 2838, '4181': 2839, '4182': 2840, '4183': 2841, '4185': 2842, '4186': 2843, '4187': 2844, '4188': 2845, '4189': 2846, '419': 2847, '4191': 2848, '4193': 2849, '4195': 2850, '4197': 2851, '4198': 2852, '42': 2853, '420': 2854, '4200': 2855, '4201': 2856, '4202': 2857, '4203': 2858, '4204': 2859, '4205': 2860, '4206': 2861, '4207': 2862, '4209': 2863, '421': 2864, '4210': 2865, '4211': 2866, '4212': 2867, '4213': 2868, '4214': 2869, '4215': 2870, '4216': 2871, '4217': 2872, '4218': 2873, '4220': 2874, '4221': 2875, '4222': 2876, '4224': 2877, '4225': 2878, '4227': 2879, '4228': 2880, '423': 2881, '4230': 2882, '4232': 2883, '4235': 2884, '4236': 2885, '4238': 2886, '4239': 2887, '424': 2888, '4240': 2889, '4242': 2890, '4243': 2891, '4245': 2892, '4246': 2893, '4247': 2894, '4248': 2895, '4249': 2896, '425': 2897, '4250': 2898, '4251': 2899, '4252': 2900, '4253': 2901, '4254': 2902, '4255': 2903, '4256': 2904, '4257': 2905, '4258': 2906, '4259': 2907, '426': 2908, '4260': 2909, '4262': 2910, '4263': 2911, '4264': 2912, '4265': 2913, '4267': 2914, '4268': 2915, '4269': 2916, '427': 2917, '4270': 2918, '4271': 2919, '4273': 2920, '4276': 2921, '4278': 2922, '4279': 2923, '428': 2924, '4280': 2925, '4281': 2926, '4282': 2927, '4283': 2928, '4284': 2929, '4285': 2930, '4286': 2931, '4287': 2932, '4288': 2933, '4289': 2934, '429': 2935, '4290': 2936, '4291': 2937, '4293': 2938, '4294': 2939, '4295': 2940, '4296': 2941, '4297': 2942, '4298': 2943, '4299': 2944, '43': 2945, '430': 2946, '4300': 2947, '4301': 2948, '4302': 2949, '4303': 2950, '4304': 2951, '4305': 2952, '4307': 2953, '4308': 2954, '4309': 2955, '431': 2956, '4310': 2957, '4311': 2958, '4313': 2959, '4314': 2960, '4315': 2961, '4316': 2962, '4317': 2963, '4319': 2964, '432': 2965, '4320': 2966, '4322': 2967, '4325': 2968, '4326': 2969, '4329': 2970, '433': 2971, '4330': 2972, '4331': 2973, '4332': 2974, '4333': 2975, '4335': 2976, '4336': 2977, '4337': 2978, '4338': 2979, '434': 2980, '4340': 2981, '4341': 2982, '4343': 2983, '4344': 2984, '4346': 2985, '4347': 2986, '4348': 2987, '4349': 2988, '4350': 2989, '4351': 2990, '4352': 2991, '4353': 2992, '4354': 2993, '4355': 2994, '4356': 2995, '4357': 2996, '4359': 2997, '436': 2998, '4360': 2999, '4361': 3000, '4362': 3001, '4363': 3002, '4364': 3003, '4365': 3004, '4368': 3005, '4369': 3006, '437': 3007, '4370': 3008, '4374': 3009, '4375': 3010, '4376': 3011, '4377': 3012, '4378': 3013, '4379': 3014, '438': 3015, '4380': 3016, '4381': 3017, '4382': 3018, '4383': 3019, '4384': 3020, '4385': 3021, '4386': 3022, '4387': 3023, '4388': 3024, '4389': 3025, '439': 3026, '4390': 3027, '4392': 3028, '4393': 3029, '4394': 3030, '4395': 3031, '4396': 3032, '4397': 3033, '4398': 3034, '4400': 3035, '4401': 3036, '4402': 3037, '4404': 3038, '4405': 3039, '4406': 3040, '4407': 3041, '4408': 3042, '4409': 3043, '441': 3044, '4410': 3045, '4413': 3046, '4414': 3047, '4415': 3048, '4416': 3049, '4417': 3050, '4418': 3051, '442': 3052, '4420': 3053, '4421': 3054, '4422': 3055, '4423': 3056, '4425': 3057, '4426': 3058, '4428': 3059, '4429': 3060, '443': 3061, '4430': 3062, '4431': 3063, '4432': 3064, '4433': 3065, '4435': 3066, '4436': 3067, '4437': 3068, '4438': 3069, '4439': 3070, '444': 3071, '4440': 3072, '4441': 3073, '4442': 3074, '4443': 3075, '4444': 3076, '4445': 3077, '4446': 3078, '4447': 3079, '445': 3080, '4450': 3081, '4452': 3082, '4453': 3083, '4454': 3084, '4455': 3085, '4456': 3086, '4457': 3087, '4458': 3088, '4459': 3089, '446': 3090, '4460': 3091, '4462': 3092, '4463': 3093, '4464': 3094, '4465': 3095, '4466': 3096, '4467': 3097, '4468': 3098, '4469': 3099, '4470': 3100, '4471': 3101, '4472': 3102, '4473': 3103, '4474': 3104, '4475': 3105, '4476': 3106, '4477': 3107, '4478': 3108, '4479': 3109, '448': 3110, '4480': 3111, '4481': 3112, '4482': 3113, '4484': 3114, '4485': 3115, '4486': 3116, '4487': 3117, '4489': 3118, '449': 3119, '4490': 3120, '4491': 3121, '4492': 3122, '4493': 3123, '4494': 3124, '4495': 3125, '4496': 3126, '4497': 3127, '4498': 3128, '4499': 3129, '45': 3130, '450': 3131, '4500': 3132, '4501': 3133, '4504': 3134, '4505': 3135, '4506': 3136, '4508': 3137, '4509': 3138, '451': 3139, '4512': 3140, '4514': 3141, '4516': 3142, '4517': 3143, '4518': 3144, '4519': 3145, '4520': 3146, '4521': 3147, '4522': 3148, '4523': 3149, '4524': 3150, '4525': 3151, '4526': 3152, '4528': 3153, '4529': 3154, '453': 3155, '4530': 3156, '4531': 3157, '4532': 3158, '4533': 3159, '4534': 3160, '4535': 3161, '4536': 3162, '4537': 3163, '4538': 3164, '454': 3165, '4540': 3166, '4541': 3167, '4542': 3168, '4543': 3169, '4544': 3170, '4545': 3171, '4546': 3172, '4548': 3173, '4549': 3174, '455': 3175, '4550': 3176, '4551': 3177, '4552': 3178, '4553': 3179, '4554': 3180, '4557': 3181, '4558': 3182, '4559': 3183, '4560': 3184, '4562': 3185, '4563': 3186, '4564': 3187, '4566': 3188, '4567': 3189, '4568': 3190, '4569': 3191, '457': 3192, '4570': 3193, '4571': 3194, '4572': 3195, '4573': 3196, '4574': 3197, '4575': 3198, '4576': 3199, '4577': 3200, '4578': 3201, '4579': 3202, '4580': 3203, '4581': 3204, '4583': 3205, '4585': 3206, '4586': 3207, '4587': 3208, '4588': 3209, '4589': 3210, '459': 3211, '4590': 3212, '4592': 3213, '4593': 3214, '4595': 3215, '4597': 3216, '4598': 3217, '4599': 3218, '46': 3219, '460': 3220, '4601': 3221, '4602': 3222, '4604': 3223, '4606': 3224, '4607': 3225, '4608': 3226, '4609': 3227, '461': 3228, '4611': 3229, '4612': 3230, '4613': 3231, '4614': 3232, '4616': 3233, '4617': 3234, '4618': 3235, '4619': 3236, '462': 3237, '4620': 3238, '4622': 3239, '4623': 3240, '4624': 3241, '4625': 3242, '4627': 3243, '4628': 3244, '4629': 3245, '463': 3246, '4630': 3247, '4631': 3248, '4632': 3249, '4633': 3250, '4634': 3251, '4635': 3252, '4638': 3253, '4639': 3254, '464': 3255, '4640': 3256, '4641': 3257, '4643': 3258, '4644': 3259, '4645': 3260, '4646': 3261, '4648': 3262, '4649': 3263, '4650': 3264, '4651': 3265, '4652': 3266, '4653': 3267, '4654': 3268, '4656': 3269, '4657': 3270, '4658': 3271, '4659': 3272, '4660': 3273, '4661': 3274, '4662': 3275, '4663': 3276, '4664': 3277, '4665': 3278, '4666': 3279, '4668': 3280, '4669': 3281, '467': 3282, '4670': 3283, '4672': 3284, '4674': 3285, '4675': 3286, '4677': 3287, '4679': 3288, '468': 3289, '4681': 3290, '4682': 3291, '4685': 3292, '4686': 3293, '4687': 3294, '4689': 3295, '469': 3296, '4690': 3297, '4691': 3298, '4692': 3299, '4693': 3300, '4695': 3301, '4696': 3302, '4697': 3303, '4698': 3304, '4699': 3305, '47': 3306, '4701': 3307, '4702': 3308, '4703': 3309, '4705': 3310, '4706': 3311, '4707': 3312, '4708': 3313, '4709': 3314, '4710': 3315, '4711': 3316, '4712': 3317, '4714': 3318, '4715': 3319, '4716': 3320, '4717': 3321, '4718': 3322, '4719': 3323, '472': 3324, '4720': 3325, '4721': 3326, '4722': 3327, '4723': 3328, '4724': 3329, '4725': 3330, '4726': 3331, '4727': 3332, '4728': 3333, '4729': 3334, '473': 3335, '4731': 3336, '4732': 3337, '4733': 3338, '4734': 3339, '4735': 3340, '4736': 3341, '4737': 3342, '4738': 3343, '4739': 3344, '474': 3345, '4740': 3346, '4741': 3347, '4742': 3348, '4743': 3349, '4744': 3350, '4745': 3351, '4746': 3352, '4747': 3353, '4748': 3354, '475': 3355, '4750': 3356, '4751': 3357, '4752': 3358, '4753': 3359, '4755': 3360, '4758': 3361, '4759': 3362, '476': 3363, '4760': 3364, '4761': 3365, '4762': 3366, '4765': 3367, '4766': 3368, '4767': 3369, '4768': 3370, '4769': 3371, '477': 3372, '4770': 3373, '4771': 3374, '4772': 3375, '4773': 3376, '4774': 3377, '4775': 3378, '4776': 3379, '4777': 3380, '4778': 3381, '4779': 3382, '478': 3383, '4780': 3384, '4781': 3385, '4782': 3386, '4784': 3387, '4785': 3388, '4786': 3389, '4787': 3390, '4789': 3391, '479': 3392, '4792': 3393, '4793': 3394, '4794': 3395, '4795': 3396, '4796': 3397, '4797': 3398, '48': 3399, '480': 3400, '4800': 3401, '4801': 3402, '4802': 3403, '4803': 3404, '4804': 3405, '4805': 3406, '4806': 3407, '4807': 3408, '4808': 3409, '4809': 3410, '4810': 3411, '4811': 3412, '4812': 3413, '4813': 3414, '4814': 3415, '4816': 3416, '4817': 3417, '4818': 3418, '4819': 3419, '482': 3420, '4820': 3421, '4822': 3422, '4823': 3423, '4825': 3424, '4826': 3425, '4827': 3426, '4828': 3427, '4829': 3428, '483': 3429, '4830': 3430, '4832': 3431, '4833': 3432, '4834': 3433, '4835': 3434, '4836': 3435, '484': 3436, '4840': 3437, '4841': 3438, '4844': 3439, '4845': 3440, '4846': 3441, '4849': 3442, '485': 3443, '4851': 3444, '4852': 3445, '4853': 3446, '4854': 3447, '4855': 3448, '4856': 3449, '4857': 3450, '4858': 3451, '4859': 3452, '486': 3453, '4860': 3454, '4861': 3455, '4862': 3456, '4863': 3457, '4864': 3458, '4866': 3459, '4867': 3460, '4869': 3461, '4870': 3462, '4871': 3463, '4872': 3464, '4873': 3465, '4874': 3466, '4876': 3467, '4878': 3468, '4879': 3469, '4880': 3470, '4881': 3471, '4883': 3472, '4886': 3473, '4887': 3474, '4888': 3475, '4889': 3476, '489': 3477, '4890': 3478, '4891': 3479, '4892': 3480, '4893': 3481, '4894': 3482, '4895': 3483, '4896': 3484, '4897': 3485, '4898': 3486, '4899': 3487, '49': 3488, '490': 3489, '4900': 3490, '4901': 3491, '4902': 3492, '4904': 3493, '4906': 3494, '4907': 3495, '4908': 3496, '4909': 3497, '491': 3498, '4910': 3499, '4912': 3500, '4914': 3501, '4915': 3502, '4916': 3503, '4919': 3504, '492': 3505, '4920': 3506, '4922': 3507, '4925': 3508, '4926': 3509, '4927': 3510, '4928': 3511, '4929': 3512, '493': 3513, '4930': 3514, '4931': 3515, '4933': 3516, '4934': 3517, '4937': 3518, '4938': 3519, '4939': 3520, '494': 3521, '4940': 3522, '4941': 3523, '4942': 3524, '4944': 3525, '4945': 3526, '4946': 3527, '4947': 3528, '4948': 3529, '4949': 3530, '495': 3531, '4951': 3532, '4952': 3533, '4953': 3534, '4955': 3535, '4956': 3536, '4957': 3537, '4958': 3538, '4960': 3539, '4961': 3540, '4963': 3541, '4966': 3542, '4967': 3543, '4968': 3544, '4969': 3545, '497': 3546, '4970': 3547, '4971': 3548, '4972': 3549, '4973': 3550, '4974': 3551, '4975': 3552, '4976': 3553, '4977': 3554, '4978': 3555, '4979': 3556, '498': 3557, '4980': 3558, '4981': 3559, '4982': 3560, '4985': 3561, '4986': 3562, '4988': 3563, '499': 3564, '4990': 3565, '4991': 3566, '4993': 3567, '4994': 3568, '4995': 3569, '4996': 3570, '4998': 3571, '4999': 3572, '5': 3573, '500': 3574, '5000': 3575, '5001': 3576, '5002': 3577, '5003': 3578, '5004': 3579, '5005': 3580, '5006': 3581, '5007': 3582, '5008': 3583, '5009': 3584, '501': 3585, '5010': 3586, '5011': 3587, '5012': 3588, '5013': 3589, '5014': 3590, '5015': 3591, '5016': 3592, '5017': 3593, '502': 3594, '5020': 3595, '5021': 3596, '5022': 3597, '5023': 3598, '5024': 3599, '5025': 3600, '5026': 3601, '5027': 3602, '5029': 3603, '503': 3604, '5030': 3605, '5031': 3606, '5034': 3607, '5036': 3608, '5037': 3609, '5038': 3610, '504': 3611, '5040': 3612, '5042': 3613, '5043': 3614, '5044': 3615, '5045': 3616, '5046': 3617, '5047': 3618, '5048': 3619, '5049': 3620, '505': 3621, '5050': 3622, '5052': 3623, '5053': 3624, '5055': 3625, '5056': 3626, '5057': 3627, '5058': 3628, '5059': 3629, '506': 3630, '5060': 3631, '5063': 3632, '5064': 3633, '5065': 3634, '5066': 3635, '5067': 3636, '5068': 3637, '5069': 3638, '507': 3639, '5070': 3640, '5071': 3641, '5072': 3642, '5073': 3643, '5074': 3644, '5075': 3645, '5076': 3646, '5077': 3647, '5078': 3648, '5079': 3649, '508': 3650, '5080': 3651, '5081': 3652, '5082': 3653, '5083': 3654, '5084': 3655, '5085': 3656, '5086': 3657, '5088': 3658, '5089': 3659, '509': 3660, '5090': 3661, '5091': 3662, '5092': 3663, '5093': 3664, '5094': 3665, '5095': 3666, '5096': 3667, '5097': 3668, '5099': 3669, '51': 3670, '510': 3671, '5101': 3672, '5103': 3673, '5106': 3674, '5107': 3675, '5108': 3676, '5110': 3677, '5111': 3678, '5113': 3679, '5114': 3680, '5116': 3681, '5117': 3682, '5118': 3683, '5119': 3684, '5120': 3685, '5121': 3686, '5122': 3687, '5123': 3688, '5124': 3689, '5125': 3690, '5126': 3691, '5128': 3692, '5129': 3693, '513': 3694, '5130': 3695, '5131': 3696, '5132': 3697, '5133': 3698, '5134': 3699, '5135': 3700, '5136': 3701, '5137': 3702, '5138': 3703, '5140': 3704, '5141': 3705, '5142': 3706, '5143': 3707, '5144': 3708, '5145': 3709, '5146': 3710, '5147': 3711, '5148': 3712, '5149': 3713, '5150': 3714, '5151': 3715, '5153': 3716, '5154': 3717, '5155': 3718, '5156': 3719, '5157': 3720, '5158': 3721, '5159': 3722, '5160': 3723, '5161': 3724, '5162': 3725, '5165': 3726, '5166': 3727, '5167': 3728, '5168': 3729, '5169': 3730, '517': 3731, '5170': 3732, '5172': 3733, '5173': 3734, '5175': 3735, '5176': 3736, '5177': 3737, '5178': 3738, '5179': 3739, '518': 3740, '5180': 3741, '5181': 3742, '5182': 3743, '5183': 3744, '5184': 3745, '5185': 3746, '5186': 3747, '5187': 3748, '5188': 3749, '5189': 3750, '519': 3751, '5191': 3752, '5192': 3753, '5193': 3754, '5194': 3755, '5195': 3756, '5196': 3757, '5198': 3758, '5199': 3759, '52': 3760, '5202': 3761, '5203': 3762, '5204': 3763, '5205': 3764, '5206': 3765, '5208': 3766, '5209': 3767, '521': 3768, '5211': 3769, '5212': 3770, '5214': 3771, '5215': 3772, '5216': 3773, '5217': 3774, '5218': 3775, '5219': 3776, '522': 3777, '5220': 3778, '5221': 3779, '5222': 3780, '5223': 3781, '5224': 3782, '5226': 3783, '5227': 3784, '5229': 3785, '523': 3786, '5230': 3787, '5232': 3788, '5234': 3789, '5235': 3790, '5237': 3791, '5238': 3792, '5239': 3793, '524': 3794, '5240': 3795, '5241': 3796, '5242': 3797, '5243': 3798, '5244': 3799, '5245': 3800, '5247': 3801, '5248': 3802, '525': 3803, '5251': 3804, '5252': 3805, '5253': 3806, '5254': 3807, '5255': 3808, '5256': 3809, '5257': 3810, '5259': 3811, '526': 3812, '5260': 3813, '5261': 3814, '5262': 3815, '5263': 3816, '5264': 3817, '5265': 3818, '5266': 3819, '5268': 3820, '5269': 3821, '527': 3822, '5270': 3823, '5271': 3824, '5273': 3825, '5274': 3826, '5275': 3827, '5276': 3828, '5278': 3829, '528': 3830, '5281': 3831, '5284': 3832, '5285': 3833, '5286': 3834, '5287': 3835, '5288': 3836, '5289': 3837, '529': 3838, '5290': 3839, '5291': 3840, '5292': 3841, '5293': 3842, '5294': 3843, '5295': 3844, '5296': 3845, '5297': 3846, '5298': 3847, '5299': 3848, '530': 3849, '5300': 3850, '5301': 3851, '5302': 3852, '5304': 3853, '5307': 3854, '5308': 3855, '5309': 3856, '531': 3857, '5310': 3858, '5312': 3859, '5313': 3860, '5314': 3861, '5315': 3862, '5316': 3863, '5317': 3864, '5318': 3865, '5319': 3866, '532': 3867, '5320': 3868, '5321': 3869, '5322': 3870, '5324': 3871, '5327': 3872, '5328': 3873, '5329': 3874, '533': 3875, '5332': 3876, '5333': 3877, '5334': 3878, '5335': 3879, '5336': 3880, '5338': 3881, '5340': 3882, '5341': 3883, '5342': 3884, '5343': 3885, '5344': 3886, '5345': 3887, '5346': 3888, '5347': 3889, '5349': 3890, '535': 3891, '5351': 3892, '5353': 3893, '5355': 3894, '5356': 3895, '5358': 3896, '5359': 3897, '536': 3898, '5360': 3899, '5361': 3900, '5362': 3901, '5365': 3902, '5366': 3903, '5368': 3904, '5369': 3905, '537': 3906, '5370': 3907, '5371': 3908, '5372': 3909, '5373': 3910, '5374': 3911, '5376': 3912, '5377': 3913, '5378': 3914, '538': 3915, '5380': 3916, '5382': 3917, '5384': 3918, '5386': 3919, '5387': 3920, '5388': 3921, '539': 3922, '5390': 3923, '5392': 3924, '5393': 3925, '5394': 3926, '5395': 3927, '5398': 3928, '5399': 3929, '54': 3930, '540': 3931, '5400': 3932, '5401': 3933, '5402': 3934, '5403': 3935, '5404': 3936, '5405': 3937, '5406': 3938, '5407': 3939, '5408': 3940, '5409': 3941, '541': 3942, '5410': 3943, '5411': 3944, '5412': 3945, '5413': 3946, '5414': 3947, '5415': 3948, '5416': 3949, '5417': 3950, '5419': 3951, '5420': 3952, '5421': 3953, '5422': 3954, '5423': 3955, '5424': 3956, '5425': 3957, '5426': 3958, '5427': 3959, '5428': 3960, '5429': 3961, '543': 3962, '5432': 3963, '5433': 3964, '5434': 3965, '5437': 3966, '5438': 3967, '5440': 3968, '5441': 3969, '5443': 3970, '5444': 3971, '5445': 3972, '5447': 3973, '5448': 3974, '5449': 3975, '545': 3976, '5452': 3977, '5453': 3978, '5454': 3979, '5456': 3980, '5457': 3981, '5458': 3982, '5459': 3983, '5461': 3984, '5462': 3985, '5464': 3986, '5465': 3987, '5466': 3988, '5467': 3989, '5469': 3990, '547': 3991, '5471': 3992, '5474': 3993, '5475': 3994, '5476': 3995, '5477': 3996, '5478': 3997, '548': 3998, '5480': 3999, '5481': 4000, '5482': 4001, '5483': 4002, '5484': 4003, '5487': 4004, '5488': 4005, '5489': 4006, '5490': 4007, '5491': 4008, '5492': 4009, '5493': 4010, '5494': 4011, '5495': 4012, '5496': 4013, '5497': 4014, '5499': 4015, '55': 4016, '550': 4017, '5500': 4018, '5501': 4019, '5502': 4020, '5504': 4021, '5505': 4022, '5508': 4023, '5509': 4024, '551': 4025, '5510': 4026, '5512': 4027, '5513': 4028, '5515': 4029, '5516': 4030, '5517': 4031, '5518': 4032, '552': 4033, '5520': 4034, '5521': 4035, '5522': 4036, '5523': 4037, '5524': 4038, '5525': 4039, '5527': 4040, '5528': 4041, '5529': 4042, '553': 4043, '5530': 4044, '5531': 4045, '5532': 4046, '5534': 4047, '5535': 4048, '5536': 4049, '5537': 4050, '5538': 4051, '5539': 4052, '554': 4053, '5540': 4054, '5542': 4055, '5543': 4056, '5545': 4057, '5546': 4058, '5548': 4059, '555': 4060, '5550': 4061, '5551': 4062, '5552': 4063, '5554': 4064, '5556': 4065, '5557': 4066, '5558': 4067, '5561': 4068, '5563': 4069, '5564': 4070, '5565': 4071, '5566': 4072, '5567': 4073, '5568': 4074, '5569': 4075, '557': 4076, '5570': 4077, '5571': 4078, '5573': 4079, '5574': 4080, '5575': 4081, '5576': 4082, '5579': 4083, '558': 4084, '5580': 4085, '5581': 4086, '5582': 4087, '5583': 4088, '5584': 4089, '5585': 4090, '5586': 4091, '5587': 4092, '5588': 4093, '5589': 4094, '559': 4095, '5590': 4096, '5592': 4097, '5593': 4098, '5594': 4099, '5595': 4100, '5596': 4101, '5598': 4102, '5599': 4103, '56': 4104, '560': 4105, '5600': 4106, '5603': 4107, '5604': 4108, '5605': 4109, '5606': 4110, '5607': 4111, '5608': 4112, '5609': 4113, '561': 4114, '5610': 4115, '5611': 4116, '5612': 4117, '5613': 4118, '5614': 4119, '5615': 4120, '5616': 4121, '5617': 4122, '5618': 4123, '562': 4124, '5620': 4125, '5621': 4126, '5623': 4127, '5625': 4128, '5626': 4129, '5627': 4130, '5628': 4131, '5629': 4132, '563': 4133, '5630': 4134, '5632': 4135, '5633': 4136, '5634': 4137, '5635': 4138, '5636': 4139, '5639': 4140, '564': 4141, '5640': 4142, '5641': 4143, '5642': 4144, '5643': 4145, '5644': 4146, '5645': 4147, '5646': 4148, '5649': 4149, '565': 4150, '5650': 4151, '5651': 4152, '5652': 4153, '5653': 4154, '5654': 4155, '5656': 4156, '5657': 4157, '5659': 4158, '566': 4159, '5661': 4160, '5663': 4161, '5664': 4162, '5665': 4163, '5666': 4164, '5667': 4165, '5668': 4166, '5669': 4167, '567': 4168, '5670': 4169, '5672': 4170, '5673': 4171, '5674': 4172, '5675': 4173, '5676': 4174, '5677': 4175, '5678': 4176, '5679': 4177, '568': 4178, '5680': 4179, '5681': 4180, '5682': 4181, '5683': 4182, '5684': 4183, '5685': 4184, '5686': 4185, '5687': 4186, '5688': 4187, '5689': 4188, '569': 4189, '5690': 4190, '5691': 4191, '5692': 4192, '5693': 4193, '5694': 4194, '5697': 4195, '5698': 4196, '5699': 4197, '57': 4198, '570': 4199, '5700': 4200, '5702': 4201, '5703': 4202, '5704': 4203, '5705': 4204, '5706': 4205, '5707': 4206, '5708': 4207, '571': 4208, '5710': 4209, '5711': 4210, '5712': 4211, '5713': 4212, '5715': 4213, '5716': 4214, '5717': 4215, '5718': 4216, '5719': 4217, '572': 4218, '5720': 4219, '5721': 4220, '5722': 4221, '5723': 4222, '5724': 4223, '5725': 4224, '5727': 4225, '5728': 4226, '5729': 4227, '573': 4228, '5730': 4229, '5732': 4230, '5733': 4231, '5734': 4232, '5735': 4233, '5736': 4234, '5737': 4235, '5739': 4236, '574': 4237, '5740': 4238, '5741': 4239, '5742': 4240, '5743': 4241, '5744': 4242, '5745': 4243, '5746': 4244, '5747': 4245, '5748': 4246, '5749': 4247, '575': 4248, '5750': 4249, '5751': 4250, '5752': 4251, '5753': 4252, '5754': 4253, '5755': 4254, '5756': 4255, '5757': 4256, '5758': 4257, '5759': 4258, '576': 4259, '5760': 4260, '5761': 4261, '5762': 4262, '5763': 4263, '5764': 4264, '5765': 4265, '5766': 4266, '5767': 4267, '5768': 4268, '5769': 4269, '577': 4270, '5770': 4271, '5771': 4272, '5772': 4273, '5773': 4274, '5775': 4275, '5777': 4276, '5778': 4277, '5779': 4278, '578': 4279, '5780': 4280, '5781': 4281, '5782': 4282, '5783': 4283, '5786': 4284, '5788': 4285, '579': 4286, '5790': 4287, '5791': 4288, '5792': 4289, '5794': 4290, '5795': 4291, '5796': 4292, '5797': 4293, '5798': 4294, '5799': 4295, '580': 4296, '5800': 4297, '5802': 4298, '5805': 4299, '5806': 4300, '5807': 4301, '5808': 4302, '5809': 4303, '581': 4304, '5810': 4305, '5811': 4306, '5812': 4307, '5815': 4308, '5816': 4309, '5817': 4310, '5818': 4311, '5819': 4312, '5820': 4313, '5821': 4314, '5823': 4315, '5826': 4316, '5828': 4317, '5829': 4318, '583': 4319, '5831': 4320, '5832': 4321, '5833': 4322, '5834': 4323, '5835': 4324, '5837': 4325, '5838': 4326, '5839': 4327, '584': 4328, '5840': 4329, '5841': 4330, '5842': 4331, '5844': 4332, '5845': 4333, '5846': 4334, '5847': 4335, '5848': 4336, '5849': 4337, '585': 4338, '5850': 4339, '5851': 4340, '5853': 4341, '5854': 4342, '5855': 4343, '5856': 4344, '5857': 4345, '5858': 4346, '5859': 4347, '5860': 4348, '5862': 4349, '5864': 4350, '5867': 4351, '5868': 4352, '5869': 4353, '587': 4354, '5870': 4355, '5872': 4356, '5873': 4357, '5874': 4358, '5875': 4359, '5877': 4360, '5878': 4361, '5879': 4362, '5880': 4363, '5882': 4364, '5883': 4365, '5885': 4366, '5886': 4367, '5887': 4368, '5888': 4369, '5889': 4370, '589': 4371, '5891': 4372, '5892': 4373, '5894': 4374, '5896': 4375, '5898': 4376, '5899': 4377, '59': 4378, '590': 4379, '5900': 4380, '5902': 4381, '5903': 4382, '5904': 4383, '5905': 4384, '5907': 4385, '5908': 4386, '5909': 4387, '591': 4388, '5910': 4389, '5911': 4390, '5913': 4391, '5915': 4392, '5916': 4393, '5917': 4394, '5918': 4395, '5919': 4396, '592': 4397, '5920': 4398, '5921': 4399, '5922': 4400, '5923': 4401, '5924': 4402, '5926': 4403, '5927': 4404, '593': 4405, '5930': 4406, '5931': 4407, '5932': 4408, '5933': 4409, '5934': 4410, '5935': 4411, '5936': 4412, '5937': 4413, '5938': 4414, '5939': 4415, '594': 4416, '5940': 4417, '5942': 4418, '5943': 4419, '5944': 4420, '5945': 4421, '5948': 4422, '5949': 4423, '595': 4424, '5950': 4425, '5951': 4426, '5952': 4427, '5953': 4428, '5954': 4429, '5955': 4430, '5956': 4431, '5957': 4432, '5958': 4433, '5959': 4434, '596': 4435, '5960': 4436, '5961': 4437, '5962': 4438, '5963': 4439, '5967': 4440, '5968': 4441, '5969': 4442, '5970': 4443, '5971': 4444, '5972': 4445, '5973': 4446, '5974': 4447, '5976': 4448, '5977': 4449, '5978': 4450, '598': 4451, '5981': 4452, '5983': 4453, '5984': 4454, '5985': 4455, '5986': 4456, '5987': 4457, '5988': 4458, '599': 4459, '5990': 4460, '5993': 4461, '5994': 4462, '5995': 4463, '5996': 4464, '5998': 4465, '5999': 4466, '6': 4467, '60': 4468, '6000': 4469, '6001': 4470, '6002': 4471, '6005': 4472, '6006': 4473, '6009': 4474, '601': 4475, '6010': 4476, '6011': 4477, '6012': 4478, '6013': 4479, '6014': 4480, '6015': 4481, '6017': 4482, '6018': 4483, '6020': 4484, '6021': 4485, '6022': 4486, '6023': 4487, '6024': 4488, '6026': 4489, '6027': 4490, '603': 4491, '6030': 4492, '6031': 4493, '6032': 4494, '6033': 4495, '6034': 4496, '6035': 4497, '6036': 4498, '6037': 4499, '6038': 4500, '6039': 4501, '604': 4502, '6040': 4503, '6041': 4504, '6042': 4505, '6043': 4506, '6044': 4507, '6046': 4508, '6047': 4509, '6048': 4510, '6049': 4511, '605': 4512, '6050': 4513, '6052': 4514, '6055': 4515, '6057': 4516, '6058': 4517, '6059': 4518, '606': 4519, '6060': 4520, '6061': 4521, '6062': 4522, '6063': 4523, '6064': 4524, '6066': 4525, '6067': 4526, '6068': 4527, '6069': 4528, '6070': 4529, '6071': 4530, '6073': 4531, '6074': 4532, '6075': 4533, '6077': 4534, '6079': 4535, '608': 4536, '6080': 4537, '6081': 4538, '6082': 4539, '6083': 4540, '6085': 4541, '6086': 4542, '6087': 4543, '6088': 4544, '6091': 4545, '6092': 4546, '6093': 4547, '6094': 4548, '6095': 4549, '6096': 4550, '6097': 4551, '6099': 4552, '610': 4553, '6101': 4554, '6103': 4555, '6104': 4556, '6105': 4557, '6106': 4558, '6107': 4559, '6108': 4560, '6109': 4561, '611': 4562, '6110': 4563, '6111': 4564, '6113': 4565, '6114': 4566, '6115': 4567, '6116': 4568, '6117': 4569, '6118': 4570, '612': 4571, '6120': 4572, '6121': 4573, '6122': 4574, '6123': 4575, '6124': 4576, '6125': 4577, '6126': 4578, '6128': 4579, '6129': 4580, '6130': 4581, '6132': 4582, '6133': 4583, '6134': 4584, '6135': 4585, '6136': 4586, '6139': 4587, '614': 4588, '6140': 4589, '6141': 4590, '6142': 4591, '6146': 4592, '6147': 4593, '6150': 4594, '6153': 4595, '6154': 4596, '6155': 4597, '6156': 4598, '6157': 4599, '6158': 4600, '6159': 4601, '616': 4602, '6160': 4603, '6162': 4604, '6164': 4605, '6165': 4606, '6166': 4607, '6167': 4608, '6168': 4609, '6169': 4610, '617': 4611, '6170': 4612, '6171': 4613, '6172': 4614, '6173': 4615, '6174': 4616, '6175': 4617, '6176': 4618, '6179': 4619, '618': 4620, '6180': 4621, '6181': 4622, '6182': 4623, '6183': 4624, '6184': 4625, '6186': 4626, '6187': 4627, '6188': 4628, '6189': 4629, '619': 4630, '6190': 4631, '6191': 4632, '6193': 4633, '6194': 4634, '6196': 4635, '6197': 4636, '6198': 4637, '6199': 4638, '62': 4639, '620': 4640, '6202': 4641, '6203': 4642, '6204': 4643, '6205': 4644, '6206': 4645, '6207': 4646, '6208': 4647, '6209': 4648, '621': 4649, '6210': 4650, '6213': 4651, '6214': 4652, '6215': 4653, '6216': 4654, '6217': 4655, '6218': 4656, '6219': 4657, '622': 4658, '6220': 4659, '6221': 4660, '6222': 4661, '6223': 4662, '6224': 4663, '6225': 4664, '6226': 4665, '6227': 4666, '6228': 4667, '6229': 4668, '623': 4669, '6230': 4670, '6231': 4671, '6232': 4672, '6233': 4673, '6235': 4674, '6237': 4675, '6238': 4676, '6239': 4677, '624': 4678, '6240': 4679, '6244': 4680, '6245': 4681, '6247': 4682, '6248': 4683, '6249': 4684, '625': 4685, '6251': 4686, '6252': 4687, '6253': 4688, '6255': 4689, '6256': 4690, '6257': 4691, '6258': 4692, '626': 4693, '6260': 4694, '6261': 4695, '6262': 4696, '6263': 4697, '6264': 4698, '6265': 4699, '6266': 4700, '6267': 4701, '6268': 4702, '6269': 4703, '627': 4704, '6270': 4705, '6271': 4706, '6272': 4707, '6273': 4708, '6274': 4709, '6275': 4710, '6276': 4711, '6277': 4712, '6278': 4713, '628': 4714, '6280': 4715, '6281': 4716, '6282': 4717, '6283': 4718, '6286': 4719, '6288': 4720, '6289': 4721, '6290': 4722, '6294': 4723, '6296': 4724, '6298': 4725, '63': 4726, '630': 4727, '6300': 4728, '6301': 4729, '6302': 4730, '6303': 4731, '6304': 4732, '6305': 4733, '6306': 4734, '6308': 4735, '6309': 4736, '631': 4737, '6311': 4738, '6312': 4739, '6313': 4740, '6314': 4741, '6315': 4742, '6316': 4743, '6318': 4744, '6319': 4745, '6320': 4746, '6321': 4747, '6323': 4748, '6324': 4749, '6325': 4750, '6326': 4751, '6327': 4752, '6329': 4753, '633': 4754, '6330': 4755, '6331': 4756, '6332': 4757, '6333': 4758, '6334': 4759, '6335': 4760, '6336': 4761, '6337': 4762, '6339': 4763, '6340': 4764, '6341': 4765, '6342': 4766, '6343': 4767, '6344': 4768, '6346': 4769, '6348': 4770, '6349': 4771, '635': 4772, '6350': 4773, '6351': 4774, '6352': 4775, '6354': 4776, '6355': 4777, '6356': 4778, '6357': 4779, '636': 4780, '6361': 4781, '6362': 4782, '6363': 4783, '6364': 4784, '6365': 4785, '6366': 4786, '6367': 4787, '6369': 4788, '637': 4789, '6370': 4790, '6372': 4791, '6373': 4792, '6374': 4793, '6375': 4794, '6377': 4795, '6378': 4796, '6379': 4797, '638': 4798, '6380': 4799, '6381': 4800, '6382': 4801, '6383': 4802, '6384': 4803, '6385': 4804, '6386': 4805, '6387': 4806, '6388': 4807, '6389': 4808, '639': 4809, '6390': 4810, '6391': 4811, '6392': 4812, '6393': 4813, '6394': 4814, '6395': 4815, '6396': 4816, '6397': 4817, '6398': 4818, '64': 4819, '640': 4820, '6401': 4821, '6402': 4822, '6403': 4823, '6404': 4824, '6407': 4825, '6408': 4826, '6409': 4827, '641': 4828, '6410': 4829, '6411': 4830, '6412': 4831, '6414': 4832, '6415': 4833, '6416': 4834, '6419': 4835, '642': 4836, '6420': 4837, '643': 4838, '644': 4839, '645': 4840, '646': 4841, '648': 4842, '65': 4843, '652': 4844, '653': 4845, '654': 4846, '656': 4847, '657': 4848, '658': 4849, '659': 4850, '660': 4851, '661': 4852, '662': 4853, '663': 4854, '664': 4855, '666': 4856, '667': 4857, '669': 4858, '67': 4859, '671': 4860, '672': 4861, '673': 4862, '674': 4863, '675': 4864, '676': 4865, '677': 4866, '678': 4867, '679': 4868, '68': 4869, '683': 4870, '684': 4871, '685': 4872, '688': 4873, '689': 4874, '69': 4875, '690': 4876, '692': 4877, '693': 4878, '694': 4879, '695': 4880, '696': 4881, '697': 4882, '699': 4883, '7': 4884, '70': 4885, '700': 4886, '701': 4887, '702': 4888, '704': 4889, '705': 4890, '706': 4891, '708': 4892, '709': 4893, '71': 4894, '711': 4895, '712': 4896, '713': 4897, '714': 4898, '715': 4899, '717': 4900, '718': 4901, '719': 4902, '72': 4903, '720': 4904, '724': 4905, '725': 4906, '727': 4907, '728': 4908, '729': 4909, '73': 4910, '730': 4911, '731': 4912, '735': 4913, '736': 4914, '737': 4915, '738': 4916, '739': 4917, '74': 4918, '740': 4919, '741': 4920, '742': 4921, '743': 4922, '744': 4923, '745': 4924, '746': 4925, '748': 4926, '750': 4927, '753': 4928, '754': 4929, '755': 4930, '756': 4931, '757': 4932, '758': 4933, '76': 4934, '761': 4935, '762': 4936, '763': 4937, '764': 4938, '766': 4939, '767': 4940, '768': 4941, '769': 4942, '770': 4943, '771': 4944, '772': 4945, '773': 4946, '775': 4947, '776': 4948, '777': 4949, '779': 4950, '78': 4951, '781': 4952, '782': 4953, '783': 4954, '784': 4955, '785': 4956, '786': 4957, '787': 4958, '788': 4959, '789': 4960, '79': 4961, '790': 4962, '792': 4963, '793': 4964, '794': 4965, '795': 4966, '796': 4967, '797': 4968, '799': 4969, '8': 4970, '80': 4971, '800': 4972, '801': 4973, '803': 4974, '804': 4975, '805': 4976, '807': 4977, '808': 4978, '809': 4979, '81': 4980, '810': 4981, '811': 4982, '813': 4983, '817': 4984, '818': 4985, '819': 4986, '82': 4987, '820': 4988, '821': 4989, '822': 4990, '824': 4991, '825': 4992, '826': 4993, '828': 4994, '829': 4995, '830': 4996, '832': 4997, '833': 4998, '834': 4999, '835': 5000, '836': 5001, '837': 5002, '838': 5003, '839': 5004, '840': 5005, '841': 5006, '842': 5007, '843': 5008, '844': 5009, '845': 5010, '846': 5011, '847': 5012, '849': 5013, '85': 5014, '850': 5015, '854': 5016, '855': 5017, '856': 5018, '857': 5019, '86': 5020, '860': 5021, '861': 5022, '863': 5023, '864': 5024, '866': 5025, '867': 5026, '868': 5027, '87': 5028, '870': 5029, '871': 5030, '873': 5031, '874': 5032, '875': 5033, '876': 5034, '877': 5035, '88': 5036, '880': 5037, '881': 5038, '882': 5039, '883': 5040, '884': 5041, '885': 5042, '886': 5043, '887': 5044, '889': 5045, '890': 5046, '891': 5047, '893': 5048, '894': 5049, '896': 5050, '897': 5051, '898': 5052, '9': 5053, '900': 5054, '902': 5055, '907': 5056, '909': 5057, '91': 5058, '910': 5059, '911': 5060, '912': 5061, '913': 5062, '914': 5063, '915': 5064, '916': 5065, '917': 5066, '918': 5067, '919': 5068, '920': 5069, '924': 5070, '925': 5071, '926': 5072, '928': 5073, '929': 5074, '93': 5075, '930': 5076, '931': 5077, '932': 5078, '933': 5079, '934': 5080, '935': 5081, '936': 5082, '937': 5083, '938': 5084, '94': 5085, '941': 5086, '942': 5087, '943': 5088, '946': 5089, '947': 5090, '948': 5091, '949': 5092, '95': 5093, '952': 5094, '953': 5095, '954': 5096, '955': 5097, '956': 5098, '957': 5099, '958': 5100, '959': 5101, '960': 5102, '961': 5103, '962': 5104, '964': 5105, '966': 5106, '967': 5107, '968': 5108, '969': 5109, '97': 5110, '970': 5111, '971': 5112, '972': 5113, '974': 5114, '975': 5115, '976': 5116, '977': 5117, '978': 5118, '979': 5119, '980': 5120, '981': 5121, '984': 5122, '985': 5123, '986': 5124, '987': 5125, '988': 5126, '989': 5127, '99': 5128, '990': 5129, '991': 5130, '994': 5131, '995': 5132, '996': 5133, '997': 5134, '998': 5135, '999': 5136})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9z_3GH6AX2r",
        "outputId": "d414d503-2d19-4ef3-aee2-aa3c075796f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHR_0wtw4XO2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HfcTlJmHWa3"
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort_key=lambda x: len(x.tweet), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device)\n",
        "\n",
        "\n",
        "\n",
        "# class_sample_count = [3,2,1] # dataset has 10 class-1 samples, 1 class-2 samples, etc.\n",
        "# weights = 1 / torch.Tensor(class_sample_count).double()\n",
        "# sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, BATCH_SIZE)\n",
        "# train_iterator = torch.utils.data.DataLoader(train_data, batch_size = BATCH_SIZE, sampler = sampler)\n",
        "# valid_iterator = torch.utils.data.DataLoader(valid_data, batch_size = BATCH_SIZE)\n",
        "# valid_iterator = torch.utils.data.DataLoader(valid_data, batch_size = BATCH_SIZE)\n",
        "# test_iterator = torch.utils.data.DataLoader(test_data, batch_size = BATCH_SIZE)\n",
        "\n",
        "# print(type(train_iterator))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY6rP1bsSK2i"
      },
      "source": [
        "# class_sample_count = [3,2,1] # dataset has 10 class-1 samples, 1 class-2 samples, etc.\n",
        "# weights = 1 / torch.Tensor(class_sample_count).double()\n",
        "# sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, BATCH_SIZE)\n",
        "# train_iterator = torch.utils.data.DataLoader(train_iterator, batch_size = BATCH_SIZE, sampler = sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaX9fJ2BHcUs",
        "outputId": "1b53463d-8160-4a74-9190-c79068464c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "cde4bb042971412f8e16695dd6d2e3ea",
            "83d4e91722a9433a9eecebf9f3172c67",
            "b9eedf58e86a4a29bdc3b8d710a40151",
            "0a8e4a71116145218b2c9246494b77af",
            "7a14fc517bec4b8ca96a0ccb29933a6b",
            "7da6db06f5e64c64ba170b5e1fd57ef1",
            "6fcb4f751c7f47f9a1669e39c6ef9c8b",
            "03f0d524274b44bb840faa6f03f117e4",
            "1d48d3f3a68b4b47a4a90e1b18595826",
            "68f22f7e1780428b942fa09569185f49",
            "d1ec708853484e01940c7e2d5b6d7d08",
            "d221f7a921de4adf8cff5eb89833efb1",
            "7fc17eb65643472690ec46bf2a2ddc9b",
            "751c634c787d4c7fa217e34b787e00b5",
            "cbdf055efbeb4abe8a9e4cea4b95a180",
            "1c6528c0ca9e4e859afc265ffc4ed13b"
          ]
        }
      },
      "source": [
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "bert = BertModel.from_pretrained(bert_model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cde4bb042971412f8e16695dd6d2e3ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d48d3f3a68b4b47a4a90e1b18595826",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1zxSgTlHmkz"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BERTGRUSentiment(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        # embedding_dim = bert.config.to_dict()['dim']\n",
        "\n",
        "        # self.conv_0 = nn.Conv2d(in_channels = 1, \n",
        "        #                         out_channels = n_filters, \n",
        "        #                         kernel_size = (filter_sizes, embedding_dim))\n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        # self.conv = nn.Conv1d(74,74, 3)\n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [batch size, sent len]\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            embedded = self.bert(text)[0]\n",
        "        #print(embedded.size())\n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\n",
        "        #print(hidden.size())\n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "        #print(hidden.size())\n",
        "        #hidden = [batch size, hid dim]\n",
        "        # hidden = hidden.unsqueeze(1)\n",
        "        output = self.out(hidden)\n",
        "        \n",
        "        #output = [batch size, out dim]\n",
        "        \n",
        "        return output\n",
        "class BERTCNNSentiment(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout,n_filters,filter_sizes):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']-3\n",
        "        self.conv_0 = nn.Conv2d(in_channels = 1, \n",
        "                                out_channels = 1, \n",
        "                                kernel_size = (2, 2))\n",
        "        self.conv_1 = nn.Conv2d(in_channels = 1, \n",
        "                                out_channels = 1, \n",
        "                                kernel_size = (3, 3))\n",
        "\n",
        "        self.pool = nn.MaxPool2d((2,1), stride=(2,1))\n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)        \n",
        "\n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [batch size, sent len]\n",
        "        # print(text.shape)\n",
        "        with torch.no_grad():\n",
        "            embedded = self.bert(text)[0]\n",
        "        #print(embedded.size())\n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #embedded = [batch size, 1, sent len, emb dim]\n",
        "        # print(embedded.size())\n",
        "        conved_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
        "        # print(pooled_0.size())\n",
        "        # print(conved_0.shape)\n",
        "        conved_1 = F.relu(self.conv_1(conved_0).squeeze(3))\n",
        "\n",
        "        # print(self.conv_0(embedded).squeeze(3).size())\n",
        "        # print(self.conv_0(embedded).size())\n",
        "\n",
        "        # print(conved_0.size())\n",
        "        # conved_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
        "        # conved_2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
        "            \n",
        "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "        \n",
        "        pooled_1 = conved_1.squeeze(1)\n",
        "        pooled_1 = self.dropout(pooled_1)\n",
        "        # print(pooled_0.size())\n",
        "\n",
        "        _, hidden = self.rnn(pooled_1)\n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "        output = self.out(hidden)\n",
        "        \n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO13qSpBH6Ey",
        "outputId": "78e7c9a2-8ab5-4515-83d1-7d2bf3d3fa1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "HIDDEN_DIM = 100\n",
        "OUTPUT_DIM = 2\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [2,3,4]\n",
        "# model = BERTGRUSentiment(bert,\n",
        "#                          HIDDEN_DIM,\n",
        "#                          OUTPUT_DIM,\n",
        "#                          N_LAYERS,\n",
        "#                          BIDIRECTIONAL,\n",
        "#                          DROPOUT)\n",
        "\n",
        "model = BERTCNNSentiment(bert,\n",
        "                         HIDDEN_DIM,\n",
        "                         OUTPUT_DIM,\n",
        "                         N_LAYERS,\n",
        "                         BIDIRECTIONAL,\n",
        "                         DROPOUT,N_FILTERS,FILTER_SIZES)\n",
        "# We can check how many parameters the model has. Our standard models have under 5M, but this one has 112M! Luckily, 110M of these parameters are from the transformer and we will not be training those.\n",
        "\n",
        "# In[100]:\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "\n",
        "# In order to freeze paramers (not train them) we need to set their `requires_grad` attribute to `False`. To do this, we simply loop through all of the `named_parameters` in our model and if they're a part of the `bert` transformer model, we set `requires_grad = False`. \n",
        "\n",
        "# In[101]:\n",
        "\n",
        "\n",
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False\n",
        "\n",
        "\n",
        "# We can now see that our model has under 3M trainable parameters, making it almost comparable to the `FastText` model. However, the text still has to propagate through the transformer which causes training to take considerably longer.\n",
        "\n",
        "# In[102]:\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 110,002,857 trainable parameters\n",
            "The model has 520,617 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrmNft5kIBWK"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "# optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# In[105]:\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Place the model and criterion onto the GPU (if available)\n",
        "\n",
        "# In[106]:\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "\n",
        "# Next, we'll define functions for: calculating accuracy, performing a training epoch, performing an evaluation epoch and calculating how long a training/evaluation epoch takes.\n",
        "\n",
        "# In[107]:\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj5JrQYo31WA"
      },
      "source": [
        "\n",
        "def categorical_accuracy(preds, y):\n",
        "    count0,count1,count2 = torch.zeros(1),torch.zeros(1),torch.zeros(1)\n",
        "    total0,total1,total2 = torch.FloatTensor(1),torch.FloatTensor(1),torch.FloatTensor(1)\n",
        "    # max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    f1 = f1_score(preds.argmax(dim = 1,keepdim = True).squeeze(1).cpu(),y.cpu())\n",
        "    cnf = confusion_matrix(preds.argmax(dim = 1,keepdim = True).squeeze(1).cpu(),y.cpu())\n",
        "\n",
        "    return f1,cnf\n",
        "    # correct = max_preds.squeeze(1).eq(y)\n",
        "    # predictions = max_preds.squeeze(1)F1 score\n",
        "    # true_correct = [0,0,0]\n",
        "    # for j,i in enumerate(y.cpu().numpy()):\n",
        "    #   true_correct[y.cpu().numpy()[j]]+=1\n",
        "    #   if i==0:\n",
        "    #     count0+=correct[j]\n",
        "    #     total0+=1\n",
        "    #   elif i==1:\n",
        "    #     count1+=correct[j]\n",
        "    #     total1+=1\n",
        "    #   elif i==2:\n",
        "    #     count2+=correct[j]\n",
        "    #   else:\n",
        "    #     total2+=1\n",
        "    # metric=torch.FloatTensor([count0/true_correct[0],count1/true_correct[1],count2/true_correct[2],f1_score(y.cpu().numpy(),predictions.cpu().numpy(),average='macro')])\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]]),metric,confusion_matrix(y.cpu().numpy(),max_preds.cpu().numpy())\n",
        "\n",
        "\n",
        "# In[108]:\n",
        "\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.tweet).squeeze(1)\n",
        "\n",
        "        # print(predictions)\n",
        "\n",
        "\n",
        "        loss = criterion(predictions, batch.label)\n",
        "\n",
        "        # print('loss',loss)\n",
        "        # (predictions.argmax(dim = 1) == batch.label).argmax(dim = 1)\n",
        "        # acc = (predictions.argmax(dim = 1) == batch.label).argmax(dim = 1).sum().item()\n",
        "        # acc = loss\n",
        "        acc,cnf = categorical_accuracy(predictions, batch.label)\n",
        "        # print(cnf)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYbK81uPIKE6"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_all_acc = torch.FloatTensor([0,0,0,0])\n",
        "    confusion_mat = torch.zeros((2,2))\n",
        "    confusion_mat_temp = torch.zeros((2,2))\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.tweet).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            # acc = all_acc = confusion_mat_temp = loss\n",
        "            acc,confusion_mat_temp = categorical_accuracy(predictions, batch.label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            # epoch_all_acc += all_acc.item()\n",
        "            confusion_mat+=confusion_mat_temp\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator),confusion_mat/len(iterator)\n",
        "\n",
        "\n",
        "# In[110]:\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt2EwZE_IB57",
        "outputId": "3afc3a7e-2d4d-4d11-899e-c864dbf74002",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "# best_valid_loss = float('inf')\n",
        "best_f1 = -1\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc,conf = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    f1 = valid_acc\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    # if valid_loss < best_valid_loss:\n",
        "    #     best_valid_loss = valid_loss\n",
        "    #     # torch.save(model.state_dict(), model_save_name)\n",
        "    #     path = os.path.join(data_path,model_save_name)\n",
        "    #     torch.save(model.state_dict(), path)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        torch.save(model.state_dict(), model_save_name)\n",
        "        path = os.path.join(data_path,model_save_name)\n",
        "        torch.save(model.state_dict(), path)\n",
        "        \n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "    # print(tot)\n",
        "    print(conf)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 54s\n",
            "\tTrain Loss: 0.254 | Train Acc: 88.84%\n",
            "\t Val. Loss: 0.319 |  Val. Acc: 80.86%\n",
            "tensor([[59.5455, 12.1818],\n",
            "        [ 1.1818, 43.8182]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWLxw5OIp2HB",
        "outputId": "31402ab5-f06d-43cb-e5e8-38f0aaaf7438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path = data_path+F\"{model_save_name}\"\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEmZVcLs4Cws"
      },
      "source": [
        "\n",
        "def test_evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_all_acc = torch.FloatTensor([[0,0],[0,0]])\n",
        "    print(epoch_all_acc)\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.tweet).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc,all_acc = test_categorical_accuracy(predictions, batch.label)\n",
        "            # print('**',all_acc)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_all_acc += all_acc\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator),epoch_all_acc/len(iterator)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,f1_score\n",
        "def test_categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    # count0,count1 = torch.zeros(1),torch.zeros(1)\n",
        "    # total0,total1 = torch.FloatTensor(1),torch.FloatTensor(1)\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    f1 = f1_score(preds.argmax(dim = 1,keepdim = True).squeeze(1).cpu(),y.cpu())\n",
        "    cnf = confusion_matrix(preds.argmax(dim = 1,keepdim = True).squeeze(1).cpu(),y.cpu())\n",
        "\n",
        "    return f1,cnf\n",
        "    # correct = max_preds.squeeze(1).eq(y)\n",
        "    # true_correct = [0,0,0]\n",
        "    # for j,i in enumerate(y.cpu().numpy()):\n",
        "    #   true_correct[y.cpu().numpy()[j]]+=1\n",
        "    #   if i==0:\n",
        "    #     count0+=correct[j]\n",
        "    #     total0+=1\n",
        "    #   elif i==1:\n",
        "    #     count1+=correct[j]\n",
        "    #     total1+=1\n",
        "    #   elif i==2:\n",
        "    #     count2+=correct[j]\n",
        "    #   else:\n",
        "    #     print(i,i==0,i==1,i==2)\n",
        "    #     total2+=1\n",
        "    # # print(count0,count1,count2,total0,total1,total2)\n",
        "    # # print([count0/total0,count1/total1,count2/total2])\n",
        "    # # print(torch.FloatTensor([count0/total0,count1/total1,count2/total2]))\n",
        "    # # print(correct.sum() / torch.FloatTensor([y.shape[0]]))\n",
        "    # # print(torch.FloatTensor([count0/total0,count1/total1,count2/total2]))\n",
        "    # print(count0,count1,count2)\n",
        "    # return correct.sum() / torch.FloatTensor([y.shape[0]]),torch.FloatTensor([count0/true_correct[0],count1/true_correct[1],count2/true_correct[2]])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IixrBAcbJeLJ",
        "outputId": "e589d480-7954-43b1-e285-643c03d31113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# model.load_state_dict(torch.load('tut6-model.pt'))\n",
        "\n",
        "test_loss, test_acc,test_all_acc = test_evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%',test_all_acc)\n",
        "\n",
        "\n",
        "# ## Inference\n",
        "# \n",
        "# We'll then use the model to test the sentiment of some sequences. We tokenize the input sequence, trim it down to the maximum length, add the special tokens to either side, convert it to a tensor, add a fake batch dimension and then pass it through our model.\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "Test Loss: 0.189 | Test Acc: 91.18% tensor([[62.0588,  4.3529],\n",
            "        [ 3.8235, 55.6471]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "829lomjFB4BT",
        "outputId": "02ae1935-cef8-4ba1-e923-cf77409e11e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(test_iterator))\n",
        "24*128"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT0Z_nLsPFe_",
        "outputId": "eabcef64-f018-46db-c7a8-a2245754dc4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoVYRr_a9qER",
        "outputId": "c888b0ea-557a-455f-fc6e-60a0f18662d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# {'1': 0, '2': 1, '0': 2})\n",
        "m = inv_map = {v: k for k, v in LABEL.vocab.stoi.items()}\n",
        "file = open('answer.txt','w')\n",
        "file.write('Uid,Sentiment\\n')\n",
        "count = 0\n",
        "for batch in test_iterator:\n",
        "  predictions = model(batch.tweet).squeeze(1)\n",
        "  max_preds = predictions.argmax(dim = 1, keepdim = True).detach().cpu().numpy()\n",
        "  # print(batch.uid)\n",
        "  # print(max_preds)\n",
        "  for i,row in enumerate(batch.id.cpu().numpy()):\n",
        "    count += 1\n",
        "    print(count)\n",
        "    if count != len(test_data):\n",
        "      file.write('%s,%s\\n'%(row,m[max_preds[i][0]]))\n",
        "    else:\n",
        "      file.write('%s,%s'%(row,m[max_preds[i][0]]))\n",
        "    # if count != len(test_data):\n",
        "    #   file.write('%s,%s,%s,%s\\n'%(row,\" \".join(tokenizer.convert_)m[max_preds[i][0]]))\n",
        "    # else:\n",
        "    #   file.write('%s,%s'%(row,m[max_preds[i][0]]))\n",
        "print(count)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n",
            "1107\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1111\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1115\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1119\n",
            "1120\n",
            "1121\n",
            "1122\n",
            "1123\n",
            "1124\n",
            "1125\n",
            "1126\n",
            "1127\n",
            "1128\n",
            "1129\n",
            "1130\n",
            "1131\n",
            "1132\n",
            "1133\n",
            "1134\n",
            "1135\n",
            "1136\n",
            "1137\n",
            "1138\n",
            "1139\n",
            "1140\n",
            "1141\n",
            "1142\n",
            "1143\n",
            "1144\n",
            "1145\n",
            "1146\n",
            "1147\n",
            "1148\n",
            "1149\n",
            "1150\n",
            "1151\n",
            "1152\n",
            "1153\n",
            "1154\n",
            "1155\n",
            "1156\n",
            "1157\n",
            "1158\n",
            "1159\n",
            "1160\n",
            "1161\n",
            "1162\n",
            "1163\n",
            "1164\n",
            "1165\n",
            "1166\n",
            "1167\n",
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1178\n",
            "1179\n",
            "1180\n",
            "1181\n",
            "1182\n",
            "1183\n",
            "1184\n",
            "1185\n",
            "1186\n",
            "1187\n",
            "1188\n",
            "1189\n",
            "1190\n",
            "1191\n",
            "1192\n",
            "1193\n",
            "1194\n",
            "1195\n",
            "1196\n",
            "1197\n",
            "1198\n",
            "1199\n",
            "1200\n",
            "1201\n",
            "1202\n",
            "1203\n",
            "1204\n",
            "1205\n",
            "1206\n",
            "1207\n",
            "1208\n",
            "1209\n",
            "1210\n",
            "1211\n",
            "1212\n",
            "1213\n",
            "1214\n",
            "1215\n",
            "1216\n",
            "1217\n",
            "1218\n",
            "1219\n",
            "1220\n",
            "1221\n",
            "1222\n",
            "1223\n",
            "1224\n",
            "1225\n",
            "1226\n",
            "1227\n",
            "1228\n",
            "1229\n",
            "1230\n",
            "1231\n",
            "1232\n",
            "1233\n",
            "1234\n",
            "1235\n",
            "1236\n",
            "1237\n",
            "1238\n",
            "1239\n",
            "1240\n",
            "1241\n",
            "1242\n",
            "1243\n",
            "1244\n",
            "1245\n",
            "1246\n",
            "1247\n",
            "1248\n",
            "1249\n",
            "1250\n",
            "1251\n",
            "1252\n",
            "1253\n",
            "1254\n",
            "1255\n",
            "1256\n",
            "1257\n",
            "1258\n",
            "1259\n",
            "1260\n",
            "1261\n",
            "1262\n",
            "1263\n",
            "1264\n",
            "1265\n",
            "1266\n",
            "1267\n",
            "1268\n",
            "1269\n",
            "1270\n",
            "1271\n",
            "1272\n",
            "1273\n",
            "1274\n",
            "1275\n",
            "1276\n",
            "1277\n",
            "1278\n",
            "1279\n",
            "1280\n",
            "1281\n",
            "1282\n",
            "1283\n",
            "1284\n",
            "1285\n",
            "1286\n",
            "1287\n",
            "1288\n",
            "1289\n",
            "1290\n",
            "1291\n",
            "1292\n",
            "1293\n",
            "1294\n",
            "1295\n",
            "1296\n",
            "1297\n",
            "1298\n",
            "1299\n",
            "1300\n",
            "1301\n",
            "1302\n",
            "1303\n",
            "1304\n",
            "1305\n",
            "1306\n",
            "1307\n",
            "1308\n",
            "1309\n",
            "1310\n",
            "1311\n",
            "1312\n",
            "1313\n",
            "1314\n",
            "1315\n",
            "1316\n",
            "1317\n",
            "1318\n",
            "1319\n",
            "1320\n",
            "1321\n",
            "1322\n",
            "1323\n",
            "1324\n",
            "1325\n",
            "1326\n",
            "1327\n",
            "1328\n",
            "1329\n",
            "1330\n",
            "1331\n",
            "1332\n",
            "1333\n",
            "1334\n",
            "1335\n",
            "1336\n",
            "1337\n",
            "1338\n",
            "1339\n",
            "1340\n",
            "1341\n",
            "1342\n",
            "1343\n",
            "1344\n",
            "1345\n",
            "1346\n",
            "1347\n",
            "1348\n",
            "1349\n",
            "1350\n",
            "1351\n",
            "1352\n",
            "1353\n",
            "1354\n",
            "1355\n",
            "1356\n",
            "1357\n",
            "1358\n",
            "1359\n",
            "1360\n",
            "1361\n",
            "1362\n",
            "1363\n",
            "1364\n",
            "1365\n",
            "1366\n",
            "1367\n",
            "1368\n",
            "1369\n",
            "1370\n",
            "1371\n",
            "1372\n",
            "1373\n",
            "1374\n",
            "1375\n",
            "1376\n",
            "1377\n",
            "1378\n",
            "1379\n",
            "1380\n",
            "1381\n",
            "1382\n",
            "1383\n",
            "1384\n",
            "1385\n",
            "1386\n",
            "1387\n",
            "1388\n",
            "1389\n",
            "1390\n",
            "1391\n",
            "1392\n",
            "1393\n",
            "1394\n",
            "1395\n",
            "1396\n",
            "1397\n",
            "1398\n",
            "1399\n",
            "1400\n",
            "1401\n",
            "1402\n",
            "1403\n",
            "1404\n",
            "1405\n",
            "1406\n",
            "1407\n",
            "1408\n",
            "1409\n",
            "1410\n",
            "1411\n",
            "1412\n",
            "1413\n",
            "1414\n",
            "1415\n",
            "1416\n",
            "1417\n",
            "1418\n",
            "1419\n",
            "1420\n",
            "1421\n",
            "1422\n",
            "1423\n",
            "1424\n",
            "1425\n",
            "1426\n",
            "1427\n",
            "1428\n",
            "1429\n",
            "1430\n",
            "1431\n",
            "1432\n",
            "1433\n",
            "1434\n",
            "1435\n",
            "1436\n",
            "1437\n",
            "1438\n",
            "1439\n",
            "1440\n",
            "1441\n",
            "1442\n",
            "1443\n",
            "1444\n",
            "1445\n",
            "1446\n",
            "1447\n",
            "1448\n",
            "1449\n",
            "1450\n",
            "1451\n",
            "1452\n",
            "1453\n",
            "1454\n",
            "1455\n",
            "1456\n",
            "1457\n",
            "1458\n",
            "1459\n",
            "1460\n",
            "1461\n",
            "1462\n",
            "1463\n",
            "1464\n",
            "1465\n",
            "1466\n",
            "1467\n",
            "1468\n",
            "1469\n",
            "1470\n",
            "1471\n",
            "1472\n",
            "1473\n",
            "1474\n",
            "1475\n",
            "1476\n",
            "1477\n",
            "1478\n",
            "1479\n",
            "1480\n",
            "1481\n",
            "1482\n",
            "1483\n",
            "1484\n",
            "1485\n",
            "1486\n",
            "1487\n",
            "1488\n",
            "1489\n",
            "1490\n",
            "1491\n",
            "1492\n",
            "1493\n",
            "1494\n",
            "1495\n",
            "1496\n",
            "1497\n",
            "1498\n",
            "1499\n",
            "1500\n",
            "1501\n",
            "1502\n",
            "1503\n",
            "1504\n",
            "1505\n",
            "1506\n",
            "1507\n",
            "1508\n",
            "1509\n",
            "1510\n",
            "1511\n",
            "1512\n",
            "1513\n",
            "1514\n",
            "1515\n",
            "1516\n",
            "1517\n",
            "1518\n",
            "1519\n",
            "1520\n",
            "1521\n",
            "1522\n",
            "1523\n",
            "1524\n",
            "1525\n",
            "1526\n",
            "1527\n",
            "1528\n",
            "1529\n",
            "1530\n",
            "1531\n",
            "1532\n",
            "1533\n",
            "1534\n",
            "1535\n",
            "1536\n",
            "1537\n",
            "1538\n",
            "1539\n",
            "1540\n",
            "1541\n",
            "1542\n",
            "1543\n",
            "1544\n",
            "1545\n",
            "1546\n",
            "1547\n",
            "1548\n",
            "1549\n",
            "1550\n",
            "1551\n",
            "1552\n",
            "1553\n",
            "1554\n",
            "1555\n",
            "1556\n",
            "1557\n",
            "1558\n",
            "1559\n",
            "1560\n",
            "1561\n",
            "1562\n",
            "1563\n",
            "1564\n",
            "1565\n",
            "1566\n",
            "1567\n",
            "1568\n",
            "1569\n",
            "1570\n",
            "1571\n",
            "1572\n",
            "1573\n",
            "1574\n",
            "1575\n",
            "1576\n",
            "1577\n",
            "1578\n",
            "1579\n",
            "1580\n",
            "1581\n",
            "1582\n",
            "1583\n",
            "1584\n",
            "1585\n",
            "1586\n",
            "1587\n",
            "1588\n",
            "1589\n",
            "1590\n",
            "1591\n",
            "1592\n",
            "1593\n",
            "1594\n",
            "1595\n",
            "1596\n",
            "1597\n",
            "1598\n",
            "1599\n",
            "1600\n",
            "1601\n",
            "1602\n",
            "1603\n",
            "1604\n",
            "1605\n",
            "1606\n",
            "1607\n",
            "1608\n",
            "1609\n",
            "1610\n",
            "1611\n",
            "1612\n",
            "1613\n",
            "1614\n",
            "1615\n",
            "1616\n",
            "1617\n",
            "1618\n",
            "1619\n",
            "1620\n",
            "1621\n",
            "1622\n",
            "1623\n",
            "1624\n",
            "1625\n",
            "1626\n",
            "1627\n",
            "1628\n",
            "1629\n",
            "1630\n",
            "1631\n",
            "1632\n",
            "1633\n",
            "1634\n",
            "1635\n",
            "1636\n",
            "1637\n",
            "1638\n",
            "1639\n",
            "1640\n",
            "1641\n",
            "1642\n",
            "1643\n",
            "1644\n",
            "1645\n",
            "1646\n",
            "1647\n",
            "1648\n",
            "1649\n",
            "1650\n",
            "1651\n",
            "1652\n",
            "1653\n",
            "1654\n",
            "1655\n",
            "1656\n",
            "1657\n",
            "1658\n",
            "1659\n",
            "1660\n",
            "1661\n",
            "1662\n",
            "1663\n",
            "1664\n",
            "1665\n",
            "1666\n",
            "1667\n",
            "1668\n",
            "1669\n",
            "1670\n",
            "1671\n",
            "1672\n",
            "1673\n",
            "1674\n",
            "1675\n",
            "1676\n",
            "1677\n",
            "1678\n",
            "1679\n",
            "1680\n",
            "1681\n",
            "1682\n",
            "1683\n",
            "1684\n",
            "1685\n",
            "1686\n",
            "1687\n",
            "1688\n",
            "1689\n",
            "1690\n",
            "1691\n",
            "1692\n",
            "1693\n",
            "1694\n",
            "1695\n",
            "1696\n",
            "1697\n",
            "1698\n",
            "1699\n",
            "1700\n",
            "1701\n",
            "1702\n",
            "1703\n",
            "1704\n",
            "1705\n",
            "1706\n",
            "1707\n",
            "1708\n",
            "1709\n",
            "1710\n",
            "1711\n",
            "1712\n",
            "1713\n",
            "1714\n",
            "1715\n",
            "1716\n",
            "1717\n",
            "1718\n",
            "1719\n",
            "1720\n",
            "1721\n",
            "1722\n",
            "1723\n",
            "1724\n",
            "1725\n",
            "1726\n",
            "1727\n",
            "1728\n",
            "1729\n",
            "1730\n",
            "1731\n",
            "1732\n",
            "1733\n",
            "1734\n",
            "1735\n",
            "1736\n",
            "1737\n",
            "1738\n",
            "1739\n",
            "1740\n",
            "1741\n",
            "1742\n",
            "1743\n",
            "1744\n",
            "1745\n",
            "1746\n",
            "1747\n",
            "1748\n",
            "1749\n",
            "1750\n",
            "1751\n",
            "1752\n",
            "1753\n",
            "1754\n",
            "1755\n",
            "1756\n",
            "1757\n",
            "1758\n",
            "1759\n",
            "1760\n",
            "1761\n",
            "1762\n",
            "1763\n",
            "1764\n",
            "1765\n",
            "1766\n",
            "1767\n",
            "1768\n",
            "1769\n",
            "1770\n",
            "1771\n",
            "1772\n",
            "1773\n",
            "1774\n",
            "1775\n",
            "1776\n",
            "1777\n",
            "1778\n",
            "1779\n",
            "1780\n",
            "1781\n",
            "1782\n",
            "1783\n",
            "1784\n",
            "1785\n",
            "1786\n",
            "1787\n",
            "1788\n",
            "1789\n",
            "1790\n",
            "1791\n",
            "1792\n",
            "1793\n",
            "1794\n",
            "1795\n",
            "1796\n",
            "1797\n",
            "1798\n",
            "1799\n",
            "1800\n",
            "1801\n",
            "1802\n",
            "1803\n",
            "1804\n",
            "1805\n",
            "1806\n",
            "1807\n",
            "1808\n",
            "1809\n",
            "1810\n",
            "1811\n",
            "1812\n",
            "1813\n",
            "1814\n",
            "1815\n",
            "1816\n",
            "1817\n",
            "1818\n",
            "1819\n",
            "1820\n",
            "1821\n",
            "1822\n",
            "1823\n",
            "1824\n",
            "1825\n",
            "1826\n",
            "1827\n",
            "1828\n",
            "1829\n",
            "1830\n",
            "1831\n",
            "1832\n",
            "1833\n",
            "1834\n",
            "1835\n",
            "1836\n",
            "1837\n",
            "1838\n",
            "1839\n",
            "1840\n",
            "1841\n",
            "1842\n",
            "1843\n",
            "1844\n",
            "1845\n",
            "1846\n",
            "1847\n",
            "1848\n",
            "1849\n",
            "1850\n",
            "1851\n",
            "1852\n",
            "1853\n",
            "1854\n",
            "1855\n",
            "1856\n",
            "1857\n",
            "1858\n",
            "1859\n",
            "1860\n",
            "1861\n",
            "1862\n",
            "1863\n",
            "1864\n",
            "1865\n",
            "1866\n",
            "1867\n",
            "1868\n",
            "1869\n",
            "1870\n",
            "1871\n",
            "1872\n",
            "1873\n",
            "1874\n",
            "1875\n",
            "1876\n",
            "1877\n",
            "1878\n",
            "1879\n",
            "1880\n",
            "1881\n",
            "1882\n",
            "1883\n",
            "1884\n",
            "1885\n",
            "1886\n",
            "1887\n",
            "1888\n",
            "1889\n",
            "1890\n",
            "1891\n",
            "1892\n",
            "1893\n",
            "1894\n",
            "1895\n",
            "1896\n",
            "1897\n",
            "1898\n",
            "1899\n",
            "1900\n",
            "1901\n",
            "1902\n",
            "1903\n",
            "1904\n",
            "1905\n",
            "1906\n",
            "1907\n",
            "1908\n",
            "1909\n",
            "1910\n",
            "1911\n",
            "1912\n",
            "1913\n",
            "1914\n",
            "1915\n",
            "1916\n",
            "1917\n",
            "1918\n",
            "1919\n",
            "1920\n",
            "1921\n",
            "1922\n",
            "1923\n",
            "1924\n",
            "1925\n",
            "1926\n",
            "1927\n",
            "1928\n",
            "1929\n",
            "1930\n",
            "1931\n",
            "1932\n",
            "1933\n",
            "1934\n",
            "1935\n",
            "1936\n",
            "1937\n",
            "1938\n",
            "1939\n",
            "1940\n",
            "1941\n",
            "1942\n",
            "1943\n",
            "1944\n",
            "1945\n",
            "1946\n",
            "1947\n",
            "1948\n",
            "1949\n",
            "1950\n",
            "1951\n",
            "1952\n",
            "1953\n",
            "1954\n",
            "1955\n",
            "1956\n",
            "1957\n",
            "1958\n",
            "1959\n",
            "1960\n",
            "1961\n",
            "1962\n",
            "1963\n",
            "1964\n",
            "1965\n",
            "1966\n",
            "1967\n",
            "1968\n",
            "1969\n",
            "1970\n",
            "1971\n",
            "1972\n",
            "1973\n",
            "1974\n",
            "1975\n",
            "1976\n",
            "1977\n",
            "1978\n",
            "1979\n",
            "1980\n",
            "1981\n",
            "1982\n",
            "1983\n",
            "1984\n",
            "1985\n",
            "1986\n",
            "1987\n",
            "1988\n",
            "1989\n",
            "1990\n",
            "1991\n",
            "1992\n",
            "1993\n",
            "1994\n",
            "1995\n",
            "1996\n",
            "1997\n",
            "1998\n",
            "1999\n",
            "2000\n",
            "2001\n",
            "2002\n",
            "2003\n",
            "2004\n",
            "2005\n",
            "2006\n",
            "2007\n",
            "2008\n",
            "2009\n",
            "2010\n",
            "2011\n",
            "2012\n",
            "2013\n",
            "2014\n",
            "2015\n",
            "2016\n",
            "2017\n",
            "2018\n",
            "2019\n",
            "2020\n",
            "2021\n",
            "2022\n",
            "2023\n",
            "2024\n",
            "2025\n",
            "2026\n",
            "2027\n",
            "2028\n",
            "2029\n",
            "2030\n",
            "2031\n",
            "2032\n",
            "2033\n",
            "2034\n",
            "2035\n",
            "2036\n",
            "2037\n",
            "2038\n",
            "2039\n",
            "2040\n",
            "2041\n",
            "2042\n",
            "2043\n",
            "2044\n",
            "2045\n",
            "2046\n",
            "2047\n",
            "2048\n",
            "2049\n",
            "2050\n",
            "2051\n",
            "2052\n",
            "2053\n",
            "2054\n",
            "2055\n",
            "2056\n",
            "2057\n",
            "2058\n",
            "2059\n",
            "2060\n",
            "2061\n",
            "2062\n",
            "2063\n",
            "2064\n",
            "2065\n",
            "2066\n",
            "2067\n",
            "2068\n",
            "2069\n",
            "2070\n",
            "2071\n",
            "2072\n",
            "2073\n",
            "2074\n",
            "2075\n",
            "2076\n",
            "2077\n",
            "2078\n",
            "2079\n",
            "2080\n",
            "2081\n",
            "2082\n",
            "2083\n",
            "2084\n",
            "2085\n",
            "2086\n",
            "2087\n",
            "2088\n",
            "2089\n",
            "2090\n",
            "2091\n",
            "2092\n",
            "2093\n",
            "2094\n",
            "2095\n",
            "2096\n",
            "2097\n",
            "2098\n",
            "2099\n",
            "2100\n",
            "2101\n",
            "2102\n",
            "2103\n",
            "2104\n",
            "2105\n",
            "2106\n",
            "2107\n",
            "2108\n",
            "2109\n",
            "2110\n",
            "2111\n",
            "2112\n",
            "2113\n",
            "2114\n",
            "2115\n",
            "2116\n",
            "2117\n",
            "2118\n",
            "2119\n",
            "2120\n",
            "2121\n",
            "2122\n",
            "2123\n",
            "2124\n",
            "2125\n",
            "2126\n",
            "2127\n",
            "2128\n",
            "2129\n",
            "2130\n",
            "2131\n",
            "2132\n",
            "2133\n",
            "2134\n",
            "2135\n",
            "2136\n",
            "2137\n",
            "2138\n",
            "2139\n",
            "2140\n",
            "2140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u54ubbMCoJlq",
        "outputId": "16ae89ff-800e-497b-b6a5-5176d2bf88c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "len(l)\n",
        "l\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-a8a4ebcf31fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laEi-ffUoSJ1"
      },
      "source": [
        "f = open('')\n",
        "for i in l:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONmKOMZmJtfk"
      },
      "source": [
        "def predict_sentiment(model, tokenizer, sentence):\n",
        "    model.eval()\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    # ind = np.argmax(np.array(prediction))\n",
        "    # if ind ==0:\n",
        "    #   print('neutral')\n",
        "    # elif ind == 1:\n",
        "    #   print(\"positive\")\n",
        "    # else:\n",
        "    #   print(\"negative\")\n",
        "    print(prediction)\n",
        "predict_sentiment(model, tokenizer, \"This film is terrible\")\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "predict_sentiment(model, tokenizer, \"This film is great\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO-V3S1HV2Oi"
      },
      "source": [
        "while True:\n",
        "  sent = input('->')\n",
        "  if sent != '$':\n",
        "    predict_sentiment(model, tokenizer, sent)\n",
        "  else:\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}